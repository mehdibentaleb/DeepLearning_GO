{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN3+NuPbtV5sLsK9ICfRZdv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nhGmUftPCzOq","executionInfo":{"status":"ok","timestamp":1673478946609,"user_tz":-60,"elapsed":73674,"user":{"displayName":"Dahab Imasbahen","userId":"12718557251442123944"}},"outputId":"566e9466-a8a8-4b8c-d468-d7d6c6793e97"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  libpython3.7-minimal libpython3.7-stdlib python3.7-minimal\n","Suggested packages:\n","  python3.7-venv binfmt-support\n","The following NEW packages will be installed:\n","  libpython3.7-minimal libpython3.7-stdlib python3.7 python3.7-minimal\n","0 upgraded, 4 newly installed, 0 to remove and 21 not upgraded.\n","Need to get 4,448 kB of archives.\n","After this operation, 22.5 MB of additional disk space will be used.\n","Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7-minimal amd64 3.7.16-1+bionic1 [589 kB]\n","Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.7-minimal amd64 3.7.16-1+bionic1 [1,725 kB]\n","Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7-stdlib amd64 3.7.16-1+bionic1 [1,773 kB]\n","Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.7 amd64 3.7.16-1+bionic1 [360 kB]\n","Fetched 4,448 kB in 3s (1,576 kB/s)\n","Selecting previously unselected package libpython3.7-minimal:amd64.\n","(Reading database ... 124016 files and directories currently installed.)\n","Preparing to unpack .../libpython3.7-minimal_3.7.16-1+bionic1_amd64.deb ...\n","Unpacking libpython3.7-minimal:amd64 (3.7.16-1+bionic1) ...\n","Selecting previously unselected package python3.7-minimal.\n","Preparing to unpack .../python3.7-minimal_3.7.16-1+bionic1_amd64.deb ...\n","Unpacking python3.7-minimal (3.7.16-1+bionic1) ...\n","Selecting previously unselected package libpython3.7-stdlib:amd64.\n","Preparing to unpack .../libpython3.7-stdlib_3.7.16-1+bionic1_amd64.deb ...\n","Unpacking libpython3.7-stdlib:amd64 (3.7.16-1+bionic1) ...\n","Selecting previously unselected package python3.7.\n","Preparing to unpack .../python3.7_3.7.16-1+bionic1_amd64.deb ...\n","Unpacking python3.7 (3.7.16-1+bionic1) ...\n","Setting up libpython3.7-minimal:amd64 (3.7.16-1+bionic1) ...\n","Setting up python3.7-minimal (3.7.16-1+bionic1) ...\n","Setting up libpython3.7-stdlib:amd64 (3.7.16-1+bionic1) ...\n","Setting up python3.7 (3.7.16-1+bionic1) ...\n","Processing triggers for mime-support (3.60ubuntu1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","update-alternatives: using /usr/bin/python3.7 to provide /usr/bin/python3 (python3) in auto mode\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'sudo apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  python-pip-whl python3-asn1crypto python3-cffi-backend python3-crypto\n","  python3-cryptography python3-idna python3-keyring python3-keyrings.alt\n","  python3-pkg-resources python3-secretstorage python3-setuptools python3-six\n","  python3-wheel python3-xdg\n","Suggested packages:\n","  python-crypto-doc python-cryptography-doc python3-cryptography-vectors\n","  gnome-keyring libkf5wallet-bin gir1.2-gnomekeyring-1.0\n","  python-secretstorage-doc python-setuptools-doc\n","The following NEW packages will be installed:\n","  python-pip-whl python3-asn1crypto python3-cffi-backend python3-crypto\n","  python3-cryptography python3-idna python3-keyring python3-keyrings.alt\n","  python3-pip python3-pkg-resources python3-secretstorage python3-setuptools\n","  python3-six python3-wheel python3-xdg\n","0 upgraded, 15 newly installed, 0 to remove and 21 not upgraded.\n","Need to get 2,882 kB of archives.\n","After this operation, 8,886 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.5 [1,653 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-asn1crypto all 0.24.0-1 [72.8 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-cffi-backend amd64 1.11.5-1 [64.6 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-idna all 2.6-1 [32.5 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-six all 1.11.0-2 [11.4 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-cryptography amd64 2.1.4-1ubuntu1.4 [220 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-secretstorage all 2.3.1-2 [12.1 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyring all 10.6.0-1 [26.7 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyrings.alt all 3.0-1 [16.6 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-pip all 9.0.1-2.3~ubuntu1.18.04.5 [114 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-setuptools all 39.0.1-2 [248 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-wheel all 0.30.0-0.2 [36.5 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-xdg all 0.25-4ubuntu1.1 [31.3 kB]\n","Fetched 2,882 kB in 0s (8,003 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 15.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package python-pip-whl.\n","(Reading database ... 124632 files and directories currently installed.)\n","Preparing to unpack .../00-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n","Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n","Selecting previously unselected package python3-asn1crypto.\n","Preparing to unpack .../01-python3-asn1crypto_0.24.0-1_all.deb ...\n","Unpacking python3-asn1crypto (0.24.0-1) ...\n","Selecting previously unselected package python3-cffi-backend.\n","Preparing to unpack .../02-python3-cffi-backend_1.11.5-1_amd64.deb ...\n","Unpacking python3-cffi-backend (1.11.5-1) ...\n","Selecting previously unselected package python3-crypto.\n","Preparing to unpack .../03-python3-crypto_2.6.1-8ubuntu2_amd64.deb ...\n","Unpacking python3-crypto (2.6.1-8ubuntu2) ...\n","Selecting previously unselected package python3-idna.\n","Preparing to unpack .../04-python3-idna_2.6-1_all.deb ...\n","Unpacking python3-idna (2.6-1) ...\n","Selecting previously unselected package python3-six.\n","Preparing to unpack .../05-python3-six_1.11.0-2_all.deb ...\n","Unpacking python3-six (1.11.0-2) ...\n","Selecting previously unselected package python3-cryptography.\n","Preparing to unpack .../06-python3-cryptography_2.1.4-1ubuntu1.4_amd64.deb ...\n","Unpacking python3-cryptography (2.1.4-1ubuntu1.4) ...\n","Selecting previously unselected package python3-secretstorage.\n","Preparing to unpack .../07-python3-secretstorage_2.3.1-2_all.deb ...\n","Unpacking python3-secretstorage (2.3.1-2) ...\n","Selecting previously unselected package python3-keyring.\n","Preparing to unpack .../08-python3-keyring_10.6.0-1_all.deb ...\n","Unpacking python3-keyring (10.6.0-1) ...\n","Selecting previously unselected package python3-keyrings.alt.\n","Preparing to unpack .../09-python3-keyrings.alt_3.0-1_all.deb ...\n","Unpacking python3-keyrings.alt (3.0-1) ...\n","Selecting previously unselected package python3-pip.\n","Preparing to unpack .../10-python3-pip_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n","Unpacking python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n","Selecting previously unselected package python3-pkg-resources.\n","Preparing to unpack .../11-python3-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python3-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python3-setuptools.\n","Preparing to unpack .../12-python3-setuptools_39.0.1-2_all.deb ...\n","Unpacking python3-setuptools (39.0.1-2) ...\n","Selecting previously unselected package python3-wheel.\n","Preparing to unpack .../13-python3-wheel_0.30.0-0.2_all.deb ...\n","Unpacking python3-wheel (0.30.0-0.2) ...\n","Selecting previously unselected package python3-xdg.\n","Preparing to unpack .../14-python3-xdg_0.25-4ubuntu1.1_all.deb ...\n","Unpacking python3-xdg (0.25-4ubuntu1.1) ...\n","Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n","Setting up python3-cffi-backend (1.11.5-1) ...\n","Setting up python3-crypto (2.6.1-8ubuntu2) ...\n","Setting up python3-idna (2.6-1) ...\n","Setting up python3-xdg (0.25-4ubuntu1.1) ...\n","Setting up python3-six (1.11.0-2) ...\n","Setting up python3-wheel (0.30.0-0.2) ...\n","Setting up python3-pkg-resources (39.0.1-2) ...\n","Setting up python3-asn1crypto (0.24.0-1) ...\n","Setting up python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n","Setting up python3-setuptools (39.0.1-2) ...\n","Setting up python3-cryptography (2.1.4-1ubuntu1.4) ...\n","Setting up python3-keyrings.alt (3.0-1) ...\n","Setting up python3-secretstorage (2.3.1-2) ...\n","Setting up python3-keyring (10.6.0-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Collecting pip\n","  Downloading https://files.pythonhosted.org/packages/09/bd/2410905c76ee14c62baf69e3f4aa780226c1bbfc9485731ad018e35b0cb5/pip-22.3.1-py3-none-any.whl (2.1MB)\n","\u001b[K    100% |████████████████████████████████| 2.1MB 685kB/s \n","\u001b[?25hInstalling collected packages: pip\n","  Found existing installation: pip 9.0.1\n","    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\n","Successfully installed pip-22.3.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pybind11\n","  Downloading pybind11-2.10.3-py3-none-any.whl (222 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.4/222.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pybind11\n","Successfully installed pybind11-2.10.3\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow\n","  Downloading tensorflow-2.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n","  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Collecting flatbuffers>=2.0\n","  Downloading flatbuffers-23.1.4-py2.py3-none-any.whl (26 kB)\n","Collecting typing-extensions>=3.6.6\n","  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n","Collecting numpy>=1.20\n","  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (39.0.1)\n","Collecting wrapt>=1.11.0\n","  Downloading wrapt-1.14.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.2/75.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting termcolor>=1.1.0\n","  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n","Collecting astunparse>=1.6.0\n","  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n","Collecting keras<2.12,>=2.11.0\n","  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting libclang>=13.0.0\n","  Downloading libclang-15.0.6.1-py2.py3-none-manylinux2010_x86_64.whl (21.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.5/21.5 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h5py>=2.9.0\n","  Downloading h5py-3.7.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n","  Downloading tensorflow_io_gcs_filesystem-0.29.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0\n","  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opt-einsum>=2.3.2\n","  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting absl-py>=1.0.0\n","  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n","  Downloading grpcio-1.51.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting packaging\n","  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard<2.12,>=2.11\n","  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting six>=1.12.0\n","  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Collecting google-pasta>=0.1.1\n","  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m282.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n","  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.30.0)\n","Collecting google-auth-oauthlib<0.5,>=0.4.1\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n","  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting requests<3,>=2.21.0\n","  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting markdown>=2.6.8\n","  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting setuptools\n","  Downloading setuptools-65.7.0-py3-none-any.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting werkzeug>=1.0.1\n","  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.7/232.7 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-auth<3,>=1.6.3\n","  Downloading google_auth-2.16.0-py2.py3-none-any.whl (177 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.8/177.8 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n","  Downloading cachetools-5.2.1-py3-none-any.whl (9.3 kB)\n","Collecting pyasn1-modules>=0.2.1\n","  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rsa<5,>=3.1.4\n","  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n","Collecting requests-oauthlib>=0.7.0\n","  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n","Collecting importlib-metadata>=4.4\n","  Downloading importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\n","Collecting certifi>=2017.4.17\n","  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.6)\n","Collecting charset-normalizer<3,>=2\n","  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n","Collecting urllib3<1.27,>=1.21.1\n","  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting MarkupSafe>=2.1.1\n","  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n","Collecting zipp>=0.5\n","  Downloading zipp-3.11.0-py3-none-any.whl (6.6 kB)\n","Collecting pyasn1<0.5.0,>=0.4.6\n","  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting oauthlib>=3.0.0\n","  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, pyasn1, libclang, flatbuffers, zipp, wrapt, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, setuptools, rsa, pyasn1-modules, protobuf, packaging, oauthlib, numpy, MarkupSafe, keras, grpcio, gast, charset-normalizer, certifi, cachetools, absl-py, werkzeug, requests, opt-einsum, importlib-metadata, h5py, google-pasta, google-auth, astunparse, requests-oauthlib, markdown, google-auth-oauthlib, tensorboard, tensorflow\n","  Attempting uninstall: six\n","    Found existing installation: six 1.11.0\n","    Uninstalling six-1.11.0:\n","      Successfully uninstalled six-1.11.0\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 39.0.1\n","    Uninstalling setuptools-39.0.1:\n","      Successfully uninstalled setuptools-39.0.1\n","Successfully installed MarkupSafe-2.1.1 absl-py-1.4.0 astunparse-1.6.3 cachetools-5.2.1 certifi-2022.12.7 charset-normalizer-2.1.1 flatbuffers-23.1.4 gast-0.4.0 google-auth-2.16.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.1 h5py-3.7.0 importlib-metadata-6.0.0 keras-2.11.0 libclang-15.0.6.1 markdown-3.4.1 numpy-1.21.6 oauthlib-3.2.2 opt-einsum-3.3.0 packaging-23.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.28.1 requests-oauthlib-1.3.1 rsa-4.9 setuptools-65.7.0 six-1.16.0 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.29.0 termcolor-2.2.0 typing-extensions-4.4.0 urllib3-1.26.14 werkzeug-2.2.2 wrapt-1.14.1 zipp-3.11.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!apt-get install python3.7\n","!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 3\n","!sudo apt install python3-pip\n","!python -m pip install --upgrade pip\n","!pip install pybind11\n","!python3 -m pip install tensorflow"]},{"cell_type":"code","source":["!sudo apt install python3.7-dev"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DBRptytaC05G","executionInfo":{"status":"ok","timestamp":1673478956993,"user_tz":-60,"elapsed":10392,"user":{"displayName":"Dahab Imasbahen","userId":"12718557251442123944"}},"outputId":"010e72f2-a417-451b-d5de-c090da7664d7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'sudo apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  libpython3.7 libpython3.7-dev\n","The following NEW packages will be installed:\n","  libpython3.7 libpython3.7-dev python3.7-dev\n","0 upgraded, 3 newly installed, 0 to remove and 21 not upgraded.\n","Need to get 44.9 MB of archives.\n","After this operation, 67.2 MB of additional disk space will be used.\n","Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7 amd64 3.7.16-1+bionic1 [1,527 kB]\n","Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7-dev amd64 3.7.16-1+bionic1 [42.9 MB]\n","Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.7-dev amd64 3.7.16-1+bionic1 [501 kB]\n","Fetched 44.9 MB in 4s (11.5 MB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libpython3.7:amd64.\n","(Reading database ... 125312 files and directories currently installed.)\n","Preparing to unpack .../libpython3.7_3.7.16-1+bionic1_amd64.deb ...\n","Unpacking libpython3.7:amd64 (3.7.16-1+bionic1) ...\n","Selecting previously unselected package libpython3.7-dev:amd64.\n","Preparing to unpack .../libpython3.7-dev_3.7.16-1+bionic1_amd64.deb ...\n","Unpacking libpython3.7-dev:amd64 (3.7.16-1+bionic1) ...\n","Selecting previously unselected package python3.7-dev.\n","Preparing to unpack .../python3.7-dev_3.7.16-1+bionic1_amd64.deb ...\n","Unpacking python3.7-dev (3.7.16-1+bionic1) ...\n","Setting up libpython3.7:amd64 (3.7.16-1+bionic1) ...\n","Setting up libpython3.7-dev:amd64 (3.7.16-1+bionic1) ...\n","Setting up python3.7-dev (3.7.16-1+bionic1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"]}]},{"cell_type":"code","source":["!wget https://www.lamsade.dauphine.fr/~cazenave/project2022.zip\n","!unzip project2022.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HY_7JiYFDfd8","executionInfo":{"status":"ok","timestamp":1673478967651,"user_tz":-60,"elapsed":10664,"user":{"displayName":"Dahab Imasbahen","userId":"12718557251442123944"}},"outputId":"2289aaa9-5b3d-4d14-df52-16fda72a422c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-01-11 23:15:56--  https://www.lamsade.dauphine.fr/~cazenave/project2022.zip\n","Resolving www.lamsade.dauphine.fr (www.lamsade.dauphine.fr)... 193.48.71.250\n","Connecting to www.lamsade.dauphine.fr (www.lamsade.dauphine.fr)|193.48.71.250|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 138784129 (132M) [application/zip]\n","Saving to: ‘project2022.zip’\n","\n","project2022.zip     100%[===================>] 132.35M  29.1MB/s    in 5.2s    \n","\n","2023-01-11 23:16:02 (25.6 MB/s) - ‘project2022.zip’ saved [138784129/138784129]\n","\n","Archive:  project2022.zip\n","  inflating: Board.h                 \n","  inflating: Game.h                  \n","  inflating: Rzone.h                 \n","  inflating: compile.sh              \n","  inflating: compileMAC.sh           \n","  inflating: games.data              \n","  inflating: golois.cpp              \n","  inflating: golois.cpython-310-x86_64-linux-gnu.so  \n","  inflating: golois.cpython-37m-x86_64-linux-gnu.so  \n","  inflating: golois.cpython-38-x86_64-linux-gnu.so  \n","  inflating: golois.py               \n","  inflating: importGolois.ipynb      \n","  inflating: zip.sh                  \n"]}]},{"cell_type":"code","source":["!sh compile.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0d9Vo3B1Dkad","executionInfo":{"status":"ok","timestamp":1673479042286,"user_tz":-60,"elapsed":6004,"user":{"displayName":"Dahab Imasbahen","userId":"12718557251442123944"}},"outputId":"4a614f80-9f0a-4f13-fdb4-b08283590444"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["In file included from \u001b[01m\u001b[Kgolois.cpp:17:0\u001b[m\u001b[K:\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kbool Board::isCapturedLadder(int, int, Rzone*)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:1767:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn1\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","    int \u001b[01;35m\u001b[Kn1\u001b[m\u001b[K = nbLiberties (inter, liberties1, stones1, 3);\n","        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:1788:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn1\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","        int \u001b[01;35m\u001b[Kn1\u001b[m\u001b[K = nbLiberties (inter, liberties1, stones1, 3);\n","            \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid Board::computeLadders(int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:1819:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kother\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","     int \u001b[01;35m\u001b[Kother\u001b[m\u001b[K = opponent (color);\n","         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid Board::computeAllLadders(int, bool)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:2065:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn1\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","     int \u001b[01;35m\u001b[Kn1\u001b[m\u001b[K = nbLiberties (i, liberties1, stones1);\n","         \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:2101:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn1\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","   int \u001b[01;35m\u001b[Kn1\u001b[m\u001b[K = nbLiberties (i, liberties1, stones1);\n","       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:2134:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn1\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","     int \u001b[01;35m\u001b[Kn1\u001b[m\u001b[K = nbLiberties (i, liberties1, stones1);\n","         \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:2171:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn1\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","   int \u001b[01;35m\u001b[Kn1\u001b[m\u001b[K = nbLiberties (i, liberties1, stones1);\n","       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid Board::computeIsInLadder()\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:2242:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn1\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","   int \u001b[01;35m\u001b[Kn1\u001b[m\u001b[K = nbLiberties (s, liberties1, stones1);\n","       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid Board::computeLostLadders()\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:2275:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn1\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","   int \u001b[01;35m\u001b[Kn1\u001b[m\u001b[K = nbLiberties (s, liberties1, stones1);\n","       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid Board::printLadders(FILE*, int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:2287:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kother\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","     int \u001b[01;35m\u001b[Kother\u001b[m\u001b[K = opponent (color);\n","         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kbool Board::sameString(int, int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:2336:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","     int \u001b[01;35m\u001b[Kn\u001b[m\u001b[K = nbLiberties (inter, liberties, stones);\n","         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kbool Board::atariLent(int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:2655:10:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Ksuggest explicit braces to avoid ambiguous ‘\u001b[01m\u001b[Kelse\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wdangling-else\u001b[m\u001b[K]\n","       if \u001b[01;35m\u001b[K(\u001b[m\u001b[Kboard [pierre - 1] == Empty)\n","          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:2658:10:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Ksuggest explicit braces to avoid ambiguous ‘\u001b[01m\u001b[Kelse\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wdangling-else\u001b[m\u001b[K]\n","       if \u001b[01;35m\u001b[K(\u001b[m\u001b[Kboard [pierre + 1] == Empty)\n","          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:2661:10:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Ksuggest explicit braces to avoid ambiguous ‘\u001b[01m\u001b[Kelse\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wdangling-else\u001b[m\u001b[K]\n","       if \u001b[01;35m\u001b[K(\u001b[m\u001b[Kboard [pierre - dxBoard] == Empty)\n","          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:2664:10:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Ksuggest explicit braces to avoid ambiguous ‘\u001b[01m\u001b[Kelse\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wdangling-else\u001b[m\u001b[K]\n","       if \u001b[01;35m\u001b[K(\u001b[m\u001b[Kboard [pierre + dxBoard] == Empty)\n","          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kint Board::playAtariIfCapture(int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:3043:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kother\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","     int \u001b[01;35m\u001b[Kother\u001b[m\u001b[K = opponent (couleur);\n","         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kint Board::captureAdjacentAtari(int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:3099:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kother\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","     int \u001b[01;35m\u001b[Kother\u001b[m\u001b[K = opponent (couleur);\n","         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kint Board::captureAtari(int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:3135:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kother\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","     int \u001b[01;35m\u001b[Kother\u001b[m\u001b[K = opponent (couleur);\n","         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kint Board::avoidCaptureAtari(int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:3158:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kother\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","     int \u001b[01;35m\u001b[Kother\u001b[m\u001b[K = opponent (couleur);\n","         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kint Board::playout(int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:3294:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Km\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n","  Move \u001b[01;35m\u001b[Km\u001b[m\u001b[K;\n","       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:3315:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ks\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","    char \u001b[01;35m\u001b[Ks\u001b[m\u001b[K [256];\n","         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kint Board::loadSGF(FILE*)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KBoard.h:3783:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kres\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","    int \u001b[01;35m\u001b[Kres\u001b[m\u001b[K = sscanf (InsideBracket, \"%d\", &sz);\n","        \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KBoard.h:3790:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ki\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","    int \u001b[01;35m\u001b[Ki\u001b[m\u001b[K = 0;\n","        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[Kgolois.cpp:18:0\u001b[m\u001b[K:\n","\u001b[01m\u001b[KGame.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid loadGamesData(char*)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KGame.h:219:129:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint*\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Kshort int*\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","         fscanf (fp, \"%d %d %f %f\", \u001b[32m\u001b[K&proGame [g] [i].inter\u001b[m\u001b[K, &proGame [g] [i].color, &proGame [g] [i].val, &proGame [g] [i].points\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n","                                    \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[KGame.h:219:129:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint*\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Kchar*\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","\u001b[01m\u001b[KGame.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid loadGamesDataVal(char*)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KGame.h:301:95:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint*\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Kshort int*\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","  fscanf (fp, \"%d %f %d \", \u001b[32m\u001b[K&proGame [g] [i].inter\u001b[m\u001b[K, &proGame [g] [i].val, &proGame [g] [i].color\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n","                           \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[KGame.h:301:95:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint*\u001b[m\u001b[K’, but argument 5 has type ‘\u001b[01m\u001b[Kchar*\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","\u001b[01m\u001b[Kgolois.cpp:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[Kgolois.cpp:70:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","  fprintf (stderr, \"r.shape = (%d, %d, %d, %d)\\n\", \u001b[32m\u001b[Kr.shape (0)\u001b[m\u001b[K, r.shape (1), r.shape (2), r.shape (3)\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n","                                                   \u001b[32m\u001b[K~~~~~~~~~~~\u001b[m\u001b[K                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[Kgolois.cpp:70:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","\u001b[01m\u001b[Kgolois.cpp:70:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 5 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","\u001b[01m\u001b[Kgolois.cpp:70:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 6 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","\u001b[01m\u001b[Kgolois.cpp:76:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kgame\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n","    int \u001b[01;35m\u001b[Kgame\u001b[m\u001b[K = positionSGF [pos].game;\n","        \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kgolois.cpp:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[Kgolois.cpp:168:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","  fprintf (stderr, \"r.shape = (%d, %d, %d, %d)\\n\", \u001b[32m\u001b[Kr.shape (0)\u001b[m\u001b[K, r.shape (1), r.shape (2), r.shape (3)\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n","                                                   \u001b[32m\u001b[K~~~~~~~~~~~\u001b[m\u001b[K                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[Kgolois.cpp:168:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","\u001b[01m\u001b[Kgolois.cpp:168:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 5 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","\u001b[01m\u001b[Kgolois.cpp:168:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 6 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","\u001b[01m\u001b[Kgolois.cpp:177:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KISO C++ forbids converting a string constant to ‘\u001b[01m\u001b[Kchar*\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wwrite-strings\u001b[m\u001b[K]\n","    loadGamesData (\"games.data\"\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n","                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[Kgolois.cpp:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[Kgolois.cpp:314:38:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KISO C++ forbids converting a string constant to ‘\u001b[01m\u001b[Kchar*\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wwrite-strings\u001b[m\u001b[K]\n","    loadGamesDataVal (\"games.val.data\"\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n","                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[Kgolois.cpp:322:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","  fprintf (stderr, \"r.shape = (%d, %d, %d, %d)\\n\", \u001b[32m\u001b[Kr.shape (0)\u001b[m\u001b[K, r.shape (1), r.shape (2), r.shape (3)\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n","                                                   \u001b[32m\u001b[K~~~~~~~~~~~\u001b[m\u001b[K                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[Kgolois.cpp:322:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","\u001b[01m\u001b[Kgolois.cpp:322:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 5 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","\u001b[01m\u001b[Kgolois.cpp:322:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 6 has type ‘\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n","In file included from \u001b[01m\u001b[Kgolois.cpp:18:0\u001b[m\u001b[K:\n","\u001b[01m\u001b[KGame.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid loadGamesData(char*)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KGame.h:206:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","     \u001b[01;35m\u001b[Kfscanf (fp, \"%d\", &nbGames)\u001b[m\u001b[K;\n","     \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KGame.h:208:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kfscanf (fp, \"%f\", &komi [g])\u001b[m\u001b[K;\n","       \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KGame.h:209:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kfscanf (fp, \"%s \", s)\u001b[m\u001b[K;\n","       \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KGame.h:212:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kfscanf (fp, \"%d\", &nbMovesSGFGame [g])\u001b[m\u001b[K;\n","       \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KGame.h:219:16:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","         \u001b[01;35m\u001b[Kfscanf (fp, \"%d %d %f %f\", &proGame [g] [i].inter, &proGame [g] [i].color, &proGame [g] [i].val, &proGame [g] [i].points)\u001b[m\u001b[K;\n","         \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KGame.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid loadGamesDataVal(char*)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[KGame.h:294:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","     \u001b[01;35m\u001b[Kfscanf (fp, \"%d\", &nbGames)\u001b[m\u001b[K;\n","     \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KGame.h:296:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kfscanf (fp, \"%s \", s)\u001b[m\u001b[K;\n","       \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KGame.h:298:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kfscanf (fp, \"%d\", &nbMovesSGFGame [g])\u001b[m\u001b[K;\n","       \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[KGame.h:301:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","  \u001b[01;35m\u001b[Kfscanf (fp, \"%d %f %d \", &proGame [g] [i].inter, &proGame [g] [i].val, &proGame [g] [i].color)\u001b[m\u001b[K;\n","  \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kgolois.cpp:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[Kgolois.cpp:213:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","      \u001b[01;35m\u001b[Kfscanf (fp, \"%d\", &nbExamples)\u001b[m\u001b[K;\n","      \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kgolois.cpp:215:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint fscanf(FILE*, const char*, ...)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","        \u001b[01;35m\u001b[Kfscanf (fp, \"%d\", &indexValidation [i])\u001b[m\u001b[K;\n","        \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n"]}]},{"cell_type":"code","source":["!python golois.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2apspRqBFpiD","executionInfo":{"status":"ok","timestamp":1673487073256,"user_tz":-60,"elapsed":7036367,"user":{"displayName":"Dahab Imasbahen","userId":"12718557251442123944"}},"outputId":"9b5e1685-fff0-4a4a-c0d6-06fc63267a20"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-01-11 23:26:34.452448: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-01-11 23:26:35.757363: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-01-11 23:26:35.757518: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-01-11 23:26:35.757544: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","getValidation\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","tcmalloc: large alloc 2400002048 bytes == 0x557fc000 @  0x7f98f3c9e887 0x7f98a0e990d9 0x7f98a0e9e85f 0x7f98a0eb306f 0x58e314 0x514581 0x5a5fb6 0x607433 0x601066 0x60112c 0x6015f6 0x64faa2 0x64fc4e 0x7f98f3899c87 0x5b64ca\n","nbPositionsSGF = 29425326\n","nbPositionsSGF = 29425326\n","loading validation.data\n","2023-01-11 23:27:03.981641: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-11 23:27:03.987229: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-11 23:27:03.987825: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-11 23:27:03.988777: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-01-11 23:27:03.989039: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-11 23:27:03.989779: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-11 23:27:03.990442: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-11 23:27:04.664521: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-11 23:27:04.665150: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-11 23:27:04.665740: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-11 23:27:04.666242: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-01-11 23:27:04.666304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13779 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," board (InputLayer)             [(None, 19, 19, 31)  0           []                               \n","                                ]                                                                 \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 19, 19, 30)   960         ['board[0][0]']                  \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 19, 19, 30)  120         ['conv2d[0][0]']                 \n"," alization)                                                                                       \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 19, 19, 152)  4560        ['batch_normalization[0][0]']    \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 19, 19, 152)  608        ['conv2d_1[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation (Activation)        (None, 19, 19, 152)  0           ['batch_normalization_1[0][0]']  \n","                                                                                                  \n"," tf.split (TFOpLambda)          [(None, 19, 19, 76)  0           ['activation[0][0]']             \n","                                , (None, 19, 19, 76                                               \n","                                )]                                                                \n","                                                                                                  \n"," depthwise_conv2d (DepthwiseCon  (None, 19, 19, 76)  760         ['tf.split[0][0]']               \n"," v2D)                                                                                             \n","                                                                                                  \n"," depthwise_conv2d_1 (DepthwiseC  (None, 19, 19, 76)  1976        ['tf.split[0][1]']               \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 19, 19, 76)  304         ['depthwise_conv2d[0][0]']       \n"," rmalization)                                                                                     \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 19, 19, 76)  304         ['depthwise_conv2d_1[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_1 (Activation)      (None, 19, 19, 76)   0           ['batch_normalization_2[0][0]']  \n","                                                                                                  \n"," activation_2 (Activation)      (None, 19, 19, 76)   0           ['batch_normalization_3[0][0]']  \n","                                                                                                  \n"," tf.concat (TFOpLambda)         (None, 19, 19, 152)  0           ['activation_1[0][0]',           \n","                                                                  'activation_2[0][0]']           \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 19, 19, 152)  608        ['tf.concat[0][0]']              \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_3 (Activation)      (None, 19, 19, 152)  0           ['batch_normalization_4[0][0]']  \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 19, 19, 30)   4560        ['activation_3[0][0]']           \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 19, 19, 30)  120         ['conv2d_2[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add (Add)                      (None, 19, 19, 30)   0           ['batch_normalization_5[0][0]',  \n","                                                                  'batch_normalization[0][0]']    \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 19, 19, 152)  4560        ['add[0][0]']                    \n","                                                                                                  \n"," batch_normalization_6 (BatchNo  (None, 19, 19, 152)  608        ['conv2d_3[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_4 (Activation)      (None, 19, 19, 152)  0           ['batch_normalization_6[0][0]']  \n","                                                                                                  \n"," tf.split_1 (TFOpLambda)        [(None, 19, 19, 76)  0           ['activation_4[0][0]']           \n","                                , (None, 19, 19, 76                                               \n","                                )]                                                                \n","                                                                                                  \n"," depthwise_conv2d_2 (DepthwiseC  (None, 19, 19, 76)  760         ['tf.split_1[0][0]']             \n"," onv2D)                                                                                           \n","                                                                                                  \n"," depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 76)  1976        ['tf.split_1[0][1]']             \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_7 (BatchNo  (None, 19, 19, 76)  304         ['depthwise_conv2d_2[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," batch_normalization_8 (BatchNo  (None, 19, 19, 76)  304         ['depthwise_conv2d_3[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_5 (Activation)      (None, 19, 19, 76)   0           ['batch_normalization_7[0][0]']  \n","                                                                                                  \n"," activation_6 (Activation)      (None, 19, 19, 76)   0           ['batch_normalization_8[0][0]']  \n","                                                                                                  \n"," tf.concat_1 (TFOpLambda)       (None, 19, 19, 152)  0           ['activation_5[0][0]',           \n","                                                                  'activation_6[0][0]']           \n","                                                                                                  \n"," batch_normalization_9 (BatchNo  (None, 19, 19, 152)  608        ['tf.concat_1[0][0]']            \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_7 (Activation)      (None, 19, 19, 152)  0           ['batch_normalization_9[0][0]']  \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 19, 19, 30)   4560        ['activation_7[0][0]']           \n","                                                                                                  \n"," batch_normalization_10 (BatchN  (None, 19, 19, 30)  120         ['conv2d_4[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_1 (Add)                    (None, 19, 19, 30)   0           ['batch_normalization_10[0][0]', \n","                                                                  'add[0][0]']                    \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 19, 19, 152)  4560        ['add_1[0][0]']                  \n","                                                                                                  \n"," batch_normalization_11 (BatchN  (None, 19, 19, 152)  608        ['conv2d_5[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_8 (Activation)      (None, 19, 19, 152)  0           ['batch_normalization_11[0][0]'] \n","                                                                                                  \n"," tf.split_2 (TFOpLambda)        [(None, 19, 19, 76)  0           ['activation_8[0][0]']           \n","                                , (None, 19, 19, 76                                               \n","                                )]                                                                \n","                                                                                                  \n"," depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 76)  760         ['tf.split_2[0][0]']             \n"," onv2D)                                                                                           \n","                                                                                                  \n"," depthwise_conv2d_5 (DepthwiseC  (None, 19, 19, 76)  1976        ['tf.split_2[0][1]']             \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_12 (BatchN  (None, 19, 19, 76)  304         ['depthwise_conv2d_4[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_13 (BatchN  (None, 19, 19, 76)  304         ['depthwise_conv2d_5[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_9 (Activation)      (None, 19, 19, 76)   0           ['batch_normalization_12[0][0]'] \n","                                                                                                  \n"," activation_10 (Activation)     (None, 19, 19, 76)   0           ['batch_normalization_13[0][0]'] \n","                                                                                                  \n"," tf.concat_2 (TFOpLambda)       (None, 19, 19, 152)  0           ['activation_9[0][0]',           \n","                                                                  'activation_10[0][0]']          \n","                                                                                                  \n"," batch_normalization_14 (BatchN  (None, 19, 19, 152)  608        ['tf.concat_2[0][0]']            \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_11 (Activation)     (None, 19, 19, 152)  0           ['batch_normalization_14[0][0]'] \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 19, 19, 30)   4560        ['activation_11[0][0]']          \n","                                                                                                  \n"," batch_normalization_15 (BatchN  (None, 19, 19, 30)  120         ['conv2d_6[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_2 (Add)                    (None, 19, 19, 30)   0           ['batch_normalization_15[0][0]', \n","                                                                  'add_1[0][0]']                  \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 19, 19, 152)  4560        ['add_2[0][0]']                  \n","                                                                                                  \n"," batch_normalization_16 (BatchN  (None, 19, 19, 152)  608        ['conv2d_7[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_12 (Activation)     (None, 19, 19, 152)  0           ['batch_normalization_16[0][0]'] \n","                                                                                                  \n"," tf.split_3 (TFOpLambda)        [(None, 19, 19, 76)  0           ['activation_12[0][0]']          \n","                                , (None, 19, 19, 76                                               \n","                                )]                                                                \n","                                                                                                  \n"," depthwise_conv2d_6 (DepthwiseC  (None, 19, 19, 76)  760         ['tf.split_3[0][0]']             \n"," onv2D)                                                                                           \n","                                                                                                  \n"," depthwise_conv2d_7 (DepthwiseC  (None, 19, 19, 76)  1976        ['tf.split_3[0][1]']             \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_17 (BatchN  (None, 19, 19, 76)  304         ['depthwise_conv2d_6[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_18 (BatchN  (None, 19, 19, 76)  304         ['depthwise_conv2d_7[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_13 (Activation)     (None, 19, 19, 76)   0           ['batch_normalization_17[0][0]'] \n","                                                                                                  \n"," activation_14 (Activation)     (None, 19, 19, 76)   0           ['batch_normalization_18[0][0]'] \n","                                                                                                  \n"," tf.concat_3 (TFOpLambda)       (None, 19, 19, 152)  0           ['activation_13[0][0]',          \n","                                                                  'activation_14[0][0]']          \n","                                                                                                  \n"," batch_normalization_19 (BatchN  (None, 19, 19, 152)  608        ['tf.concat_3[0][0]']            \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_15 (Activation)     (None, 19, 19, 152)  0           ['batch_normalization_19[0][0]'] \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 19, 19, 30)   4560        ['activation_15[0][0]']          \n","                                                                                                  \n"," batch_normalization_20 (BatchN  (None, 19, 19, 30)  120         ['conv2d_8[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_3 (Add)                    (None, 19, 19, 30)   0           ['batch_normalization_20[0][0]', \n","                                                                  'add_2[0][0]']                  \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 19, 19, 152)  4560        ['add_3[0][0]']                  \n","                                                                                                  \n"," batch_normalization_21 (BatchN  (None, 19, 19, 152)  608        ['conv2d_9[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_16 (Activation)     (None, 19, 19, 152)  0           ['batch_normalization_21[0][0]'] \n","                                                                                                  \n"," tf.split_4 (TFOpLambda)        [(None, 19, 19, 76)  0           ['activation_16[0][0]']          \n","                                , (None, 19, 19, 76                                               \n","                                )]                                                                \n","                                                                                                  \n"," depthwise_conv2d_8 (DepthwiseC  (None, 19, 19, 76)  760         ['tf.split_4[0][0]']             \n"," onv2D)                                                                                           \n","                                                                                                  \n"," depthwise_conv2d_9 (DepthwiseC  (None, 19, 19, 76)  1976        ['tf.split_4[0][1]']             \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_22 (BatchN  (None, 19, 19, 76)  304         ['depthwise_conv2d_8[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_23 (BatchN  (None, 19, 19, 76)  304         ['depthwise_conv2d_9[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_17 (Activation)     (None, 19, 19, 76)   0           ['batch_normalization_22[0][0]'] \n","                                                                                                  \n"," activation_18 (Activation)     (None, 19, 19, 76)   0           ['batch_normalization_23[0][0]'] \n","                                                                                                  \n"," tf.concat_4 (TFOpLambda)       (None, 19, 19, 152)  0           ['activation_17[0][0]',          \n","                                                                  'activation_18[0][0]']          \n","                                                                                                  \n"," batch_normalization_24 (BatchN  (None, 19, 19, 152)  608        ['tf.concat_4[0][0]']            \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_19 (Activation)     (None, 19, 19, 152)  0           ['batch_normalization_24[0][0]'] \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 19, 19, 30)   4560        ['activation_19[0][0]']          \n","                                                                                                  \n"," batch_normalization_25 (BatchN  (None, 19, 19, 30)  120         ['conv2d_10[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_4 (Add)                    (None, 19, 19, 30)   0           ['batch_normalization_25[0][0]', \n","                                                                  'add_3[0][0]']                  \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 19, 19, 152)  4560        ['add_4[0][0]']                  \n","                                                                                                  \n"," batch_normalization_26 (BatchN  (None, 19, 19, 152)  608        ['conv2d_11[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_20 (Activation)     (None, 19, 19, 152)  0           ['batch_normalization_26[0][0]'] \n","                                                                                                  \n"," tf.split_5 (TFOpLambda)        [(None, 19, 19, 76)  0           ['activation_20[0][0]']          \n","                                , (None, 19, 19, 76                                               \n","                                )]                                                                \n","                                                                                                  \n"," depthwise_conv2d_10 (Depthwise  (None, 19, 19, 76)  760         ['tf.split_5[0][0]']             \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," depthwise_conv2d_11 (Depthwise  (None, 19, 19, 76)  1976        ['tf.split_5[0][1]']             \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_27 (BatchN  (None, 19, 19, 76)  304         ['depthwise_conv2d_10[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_28 (BatchN  (None, 19, 19, 76)  304         ['depthwise_conv2d_11[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_21 (Activation)     (None, 19, 19, 76)   0           ['batch_normalization_27[0][0]'] \n","                                                                                                  \n"," activation_22 (Activation)     (None, 19, 19, 76)   0           ['batch_normalization_28[0][0]'] \n","                                                                                                  \n"," tf.concat_5 (TFOpLambda)       (None, 19, 19, 152)  0           ['activation_21[0][0]',          \n","                                                                  'activation_22[0][0]']          \n","                                                                                                  \n"," batch_normalization_29 (BatchN  (None, 19, 19, 152)  608        ['tf.concat_5[0][0]']            \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_23 (Activation)     (None, 19, 19, 152)  0           ['batch_normalization_29[0][0]'] \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 19, 19, 30)   4560        ['activation_23[0][0]']          \n","                                                                                                  \n"," batch_normalization_30 (BatchN  (None, 19, 19, 30)  120         ['conv2d_12[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_5 (Add)                    (None, 19, 19, 30)   0           ['batch_normalization_30[0][0]', \n","                                                                  'add_4[0][0]']                  \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 19, 19, 152)  4560        ['add_5[0][0]']                  \n","                                                                                                  \n"," batch_normalization_31 (BatchN  (None, 19, 19, 152)  608        ['conv2d_13[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_24 (Activation)     (None, 19, 19, 152)  0           ['batch_normalization_31[0][0]'] \n","                                                                                                  \n"," tf.split_6 (TFOpLambda)        [(None, 19, 19, 76)  0           ['activation_24[0][0]']          \n","                                , (None, 19, 19, 76                                               \n","                                )]                                                                \n","                                                                                                  \n"," depthwise_conv2d_12 (Depthwise  (None, 19, 19, 76)  760         ['tf.split_6[0][0]']             \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," depthwise_conv2d_13 (Depthwise  (None, 19, 19, 76)  1976        ['tf.split_6[0][1]']             \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_32 (BatchN  (None, 19, 19, 76)  304         ['depthwise_conv2d_12[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_33 (BatchN  (None, 19, 19, 76)  304         ['depthwise_conv2d_13[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_25 (Activation)     (None, 19, 19, 76)   0           ['batch_normalization_32[0][0]'] \n","                                                                                                  \n"," activation_26 (Activation)     (None, 19, 19, 76)   0           ['batch_normalization_33[0][0]'] \n","                                                                                                  \n"," tf.concat_6 (TFOpLambda)       (None, 19, 19, 152)  0           ['activation_25[0][0]',          \n","                                                                  'activation_26[0][0]']          \n","                                                                                                  \n"," batch_normalization_34 (BatchN  (None, 19, 19, 152)  608        ['tf.concat_6[0][0]']            \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_27 (Activation)     (None, 19, 19, 152)  0           ['batch_normalization_34[0][0]'] \n","                                                                                                  \n"," conv2d_14 (Conv2D)             (None, 19, 19, 30)   4560        ['activation_27[0][0]']          \n","                                                                                                  \n"," batch_normalization_35 (BatchN  (None, 19, 19, 30)  120         ['conv2d_14[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_6 (Add)                    (None, 19, 19, 30)   0           ['batch_normalization_35[0][0]', \n","                                                                  'add_5[0][0]']                  \n","                                                                                                  \n"," global_average_pooling2d_7 (Gl  (None, 30)          0           ['add_6[0][0]']                  \n"," obalAveragePooling2D)                                                                            \n","                                                                                                  \n"," dense (Dense)                  (None, 50)           1550        ['global_average_pooling2d_7[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," conv2d_15 (Conv2D)             (None, 19, 19, 1)    30          ['add_6[0][0]']                  \n","                                                                                                  \n"," dense_1 (Dense)                (None, 12)           612         ['dense[0][0]']                  \n","                                                                                                  \n"," flatten (Flatten)              (None, 361)          0           ['conv2d_15[0][0]']              \n","                                                                                                  \n"," dense_2 (Dense)                (None, 4)            52          ['dense_1[0][0]']                \n","                                                                                                  \n"," policy (Activation)            (None, 361)          0           ['flatten[0][0]']                \n","                                                                                                  \n"," value (Dense)                  (None, 1)            5           ['dense_2[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 99,929\n","Trainable params: 93,065\n","Non-trainable params: 6,864\n","__________________________________________________________________________________________________\n","epoch 1\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-11 23:27:07.289848: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","2023-01-11 23:27:15.098338: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8101\n","2023-01-11 23:27:16.553395: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x10bddaa80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-01-11 23:27:16.553447: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2023-01-11 23:27:16.670590: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","79/79 [==============================] - 22s 132ms/step - loss: 5.2122 - policy_loss: 4.4425 - value_loss: 0.6929 - policy_categorical_accuracy: 0.1384 - value_mse: 0.1213\n","epoch 2\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-11 23:27:36.447593: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","79/79 [==============================] - 10s 131ms/step - loss: 4.5410 - policy_loss: 3.7741 - value_loss: 0.6899 - policy_categorical_accuracy: 0.2064 - value_mse: 0.1178\n","epoch 3\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-11 23:27:48.773213: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","79/79 [==============================] - 10s 131ms/step - loss: 4.2144 - policy_loss: 3.4483 - value_loss: 0.6891 - policy_categorical_accuracy: 0.2462 - value_mse: 0.1184\n","epoch 4\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-11 23:28:10.978929: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","79/79 [==============================] - 10s 131ms/step - loss: 4.0142 - policy_loss: 3.2500 - value_loss: 0.6871 - policy_categorical_accuracy: 0.2768 - value_mse: 0.1178\n","epoch 5\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","2023-01-11 23:28:23.265598: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n","79/79 [==============================] - 10s 132ms/step - loss: 4.1724 - policy_loss: 3.4058 - value_loss: 0.6894 - policy_categorical_accuracy: 0.2561 - value_mse: 0.1177\n","epoch 6\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.9353 - policy_loss: 3.1713 - value_loss: 0.6867 - policy_categorical_accuracy: 0.2826 - value_mse: 0.1148\n","epoch 7\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.8517 - policy_loss: 3.0890 - value_loss: 0.6855 - policy_categorical_accuracy: 0.2996 - value_mse: 0.1164\n","epoch 8\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 132ms/step - loss: 3.7498 - policy_loss: 2.9868 - value_loss: 0.6858 - policy_categorical_accuracy: 0.3127 - value_mse: 0.1162\n","epoch 9\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.7603 - policy_loss: 2.9975 - value_loss: 0.6856 - policy_categorical_accuracy: 0.3105 - value_mse: 0.1153\n","epoch 10\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.9142 - policy_loss: 3.1511 - value_loss: 0.6859 - policy_categorical_accuracy: 0.2878 - value_mse: 0.1155\n","epoch 11\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.7875 - policy_loss: 3.0266 - value_loss: 0.6837 - policy_categorical_accuracy: 0.3039 - value_mse: 0.1166\n","epoch 12\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.7264 - policy_loss: 2.9672 - value_loss: 0.6819 - policy_categorical_accuracy: 0.3090 - value_mse: 0.1148\n","epoch 13\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.6708 - policy_loss: 2.9166 - value_loss: 0.6770 - policy_categorical_accuracy: 0.3211 - value_mse: 0.1112\n","epoch 14\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.6439 - policy_loss: 2.8930 - value_loss: 0.6738 - policy_categorical_accuracy: 0.3250 - value_mse: 0.1083\n","epoch 15\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.6414 - policy_loss: 2.8898 - value_loss: 0.6746 - policy_categorical_accuracy: 0.3247 - value_mse: 0.1112\n","epoch 16\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.5887 - policy_loss: 2.8405 - value_loss: 0.6712 - policy_categorical_accuracy: 0.3298 - value_mse: 0.1077\n","epoch 17\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.5936 - policy_loss: 2.8458 - value_loss: 0.6708 - policy_categorical_accuracy: 0.3263 - value_mse: 0.1077\n","epoch 18\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.5575 - policy_loss: 2.8132 - value_loss: 0.6674 - policy_categorical_accuracy: 0.3325 - value_mse: 0.1087\n","epoch 19\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.5596 - policy_loss: 2.8133 - value_loss: 0.6693 - policy_categorical_accuracy: 0.3362 - value_mse: 0.1061\n","epoch 20\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.6581 - policy_loss: 2.9059 - value_loss: 0.6753 - policy_categorical_accuracy: 0.3161 - value_mse: 0.1120\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [4.387185096740723, 3.589984655380249, 0.7202196717262268, 0.24269999563694, 0.13178589940071106]\n","epoch 21\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.6370 - policy_loss: 2.8919 - value_loss: 0.6681 - policy_categorical_accuracy: 0.3150 - value_mse: 0.1073\n","epoch 22\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.6444 - policy_loss: 2.8942 - value_loss: 0.6733 - policy_categorical_accuracy: 0.3188 - value_mse: 0.1106\n","epoch 23\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.5985 - policy_loss: 2.8528 - value_loss: 0.6688 - policy_categorical_accuracy: 0.3277 - value_mse: 0.1083\n","epoch 24\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.5914 - policy_loss: 2.8497 - value_loss: 0.6648 - policy_categorical_accuracy: 0.3268 - value_mse: 0.1066\n","epoch 25\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.5735 - policy_loss: 2.8294 - value_loss: 0.6673 - policy_categorical_accuracy: 0.3315 - value_mse: 0.1066\n","epoch 26\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.5644 - policy_loss: 2.8231 - value_loss: 0.6645 - policy_categorical_accuracy: 0.3277 - value_mse: 0.1048\n","epoch 27\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.5024 - policy_loss: 2.7615 - value_loss: 0.6641 - policy_categorical_accuracy: 0.3346 - value_mse: 0.1071\n","epoch 28\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.4814 - policy_loss: 2.7405 - value_loss: 0.6642 - policy_categorical_accuracy: 0.3467 - value_mse: 0.1054\n","epoch 29\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.4775 - policy_loss: 2.7434 - value_loss: 0.6575 - policy_categorical_accuracy: 0.3455 - value_mse: 0.1021\n","epoch 30\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.4070 - policy_loss: 2.6721 - value_loss: 0.6584 - policy_categorical_accuracy: 0.3488 - value_mse: 0.1033\n","epoch 31\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.4520 - policy_loss: 2.7163 - value_loss: 0.6592 - policy_categorical_accuracy: 0.3397 - value_mse: 0.1023\n","epoch 32\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.4323 - policy_loss: 2.6983 - value_loss: 0.6575 - policy_categorical_accuracy: 0.3507 - value_mse: 0.1017\n","epoch 33\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.4312 - policy_loss: 2.6977 - value_loss: 0.6571 - policy_categorical_accuracy: 0.3544 - value_mse: 0.1015\n","epoch 34\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.4092 - policy_loss: 2.6801 - value_loss: 0.6527 - policy_categorical_accuracy: 0.3529 - value_mse: 0.1009\n","epoch 35\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.3789 - policy_loss: 2.6462 - value_loss: 0.6563 - policy_categorical_accuracy: 0.3637 - value_mse: 0.1008\n","epoch 36\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.3927 - policy_loss: 2.6623 - value_loss: 0.6541 - policy_categorical_accuracy: 0.3585 - value_mse: 0.1021\n","epoch 37\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.3804 - policy_loss: 2.6518 - value_loss: 0.6523 - policy_categorical_accuracy: 0.3589 - value_mse: 0.1010\n","epoch 38\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.4194 - policy_loss: 2.6858 - value_loss: 0.6572 - policy_categorical_accuracy: 0.3485 - value_mse: 0.1037\n","epoch 39\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.4075 - policy_loss: 2.6751 - value_loss: 0.6560 - policy_categorical_accuracy: 0.3481 - value_mse: 0.1019\n","epoch 40\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.4795 - policy_loss: 2.7443 - value_loss: 0.6589 - policy_categorical_accuracy: 0.3492 - value_mse: 0.1009\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [4.268538475036621, 3.473139524459839, 0.7190709710121155, 0.24240000545978546, 0.1277165710926056]\n","epoch 41\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.5131 - policy_loss: 2.7708 - value_loss: 0.6659 - policy_categorical_accuracy: 0.3351 - value_mse: 0.1060\n","epoch 42\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.4786 - policy_loss: 2.7407 - value_loss: 0.6616 - policy_categorical_accuracy: 0.3394 - value_mse: 0.1060\n","epoch 43\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.4372 - policy_loss: 2.6962 - value_loss: 0.6648 - policy_categorical_accuracy: 0.3477 - value_mse: 0.1056\n","epoch 44\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.4304 - policy_loss: 2.6935 - value_loss: 0.6606 - policy_categorical_accuracy: 0.3491 - value_mse: 0.1038\n","epoch 45\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.4336 - policy_loss: 2.6984 - value_loss: 0.6590 - policy_categorical_accuracy: 0.3472 - value_mse: 0.1028\n","epoch 46\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 132ms/step - loss: 3.4471 - policy_loss: 2.7118 - value_loss: 0.6591 - policy_categorical_accuracy: 0.3438 - value_mse: 0.1032\n","epoch 47\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.4127 - policy_loss: 2.6773 - value_loss: 0.6593 - policy_categorical_accuracy: 0.3569 - value_mse: 0.1049\n","epoch 48\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.4272 - policy_loss: 2.6897 - value_loss: 0.6614 - policy_categorical_accuracy: 0.3456 - value_mse: 0.1059\n","epoch 49\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.4056 - policy_loss: 2.6726 - value_loss: 0.6569 - policy_categorical_accuracy: 0.3506 - value_mse: 0.1037\n","epoch 50\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.3672 - policy_loss: 2.6358 - value_loss: 0.6554 - policy_categorical_accuracy: 0.3547 - value_mse: 0.1028\n","epoch 51\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.3965 - policy_loss: 2.6656 - value_loss: 0.6550 - policy_categorical_accuracy: 0.3514 - value_mse: 0.1032\n","epoch 52\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.3863 - policy_loss: 2.6548 - value_loss: 0.6557 - policy_categorical_accuracy: 0.3473 - value_mse: 0.0999\n","epoch 53\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.4051 - policy_loss: 2.6775 - value_loss: 0.6518 - policy_categorical_accuracy: 0.3452 - value_mse: 0.1000\n","epoch 54\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.3742 - policy_loss: 2.6427 - value_loss: 0.6557 - policy_categorical_accuracy: 0.3537 - value_mse: 0.1014\n","epoch 55\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.3696 - policy_loss: 2.6408 - value_loss: 0.6531 - policy_categorical_accuracy: 0.3577 - value_mse: 0.1009\n","epoch 56\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.3634 - policy_loss: 2.6300 - value_loss: 0.6577 - policy_categorical_accuracy: 0.3578 - value_mse: 0.1036\n","epoch 57\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.3409 - policy_loss: 2.6061 - value_loss: 0.6591 - policy_categorical_accuracy: 0.3596 - value_mse: 0.1054\n","epoch 58\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.3372 - policy_loss: 2.6089 - value_loss: 0.6528 - policy_categorical_accuracy: 0.3584 - value_mse: 0.1010\n","epoch 59\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.3250 - policy_loss: 2.5940 - value_loss: 0.6555 - policy_categorical_accuracy: 0.3638 - value_mse: 0.1026\n","epoch 60\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.3259 - policy_loss: 2.6009 - value_loss: 0.6496 - policy_categorical_accuracy: 0.3592 - value_mse: 0.0995\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.4459383487701416, 2.6834237575531006, 0.6871176958084106, 0.349700003862381, 0.11669742316007614]\n","epoch 61\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.3125 - policy_loss: 2.5839 - value_loss: 0.6532 - policy_categorical_accuracy: 0.3595 - value_mse: 0.1014\n","epoch 62\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.3103 - policy_loss: 2.5840 - value_loss: 0.6510 - policy_categorical_accuracy: 0.3595 - value_mse: 0.1002\n","epoch 63\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.2781 - policy_loss: 2.5501 - value_loss: 0.6527 - policy_categorical_accuracy: 0.3651 - value_mse: 0.0994\n","epoch 64\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.2980 - policy_loss: 2.5752 - value_loss: 0.6476 - policy_categorical_accuracy: 0.3614 - value_mse: 0.0989\n","epoch 65\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.2933 - policy_loss: 2.5671 - value_loss: 0.6511 - policy_categorical_accuracy: 0.3654 - value_mse: 0.1011\n","epoch 66\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 136ms/step - loss: 3.2745 - policy_loss: 2.5534 - value_loss: 0.6460 - policy_categorical_accuracy: 0.3648 - value_mse: 0.0972\n","epoch 67\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.2757 - policy_loss: 2.5536 - value_loss: 0.6471 - policy_categorical_accuracy: 0.3693 - value_mse: 0.0968\n","epoch 68\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.2664 - policy_loss: 2.5408 - value_loss: 0.6506 - policy_categorical_accuracy: 0.3726 - value_mse: 0.0997\n","epoch 69\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.2781 - policy_loss: 2.5569 - value_loss: 0.6461 - policy_categorical_accuracy: 0.3673 - value_mse: 0.0982\n","epoch 70\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.2579 - policy_loss: 2.5368 - value_loss: 0.6462 - policy_categorical_accuracy: 0.3721 - value_mse: 0.0982\n","epoch 71\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 132ms/step - loss: 3.2870 - policy_loss: 2.5661 - value_loss: 0.6459 - policy_categorical_accuracy: 0.3626 - value_mse: 0.0982\n","epoch 72\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.2446 - policy_loss: 2.5265 - value_loss: 0.6432 - policy_categorical_accuracy: 0.3762 - value_mse: 0.0968\n","epoch 73\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.2543 - policy_loss: 2.5302 - value_loss: 0.6492 - policy_categorical_accuracy: 0.3744 - value_mse: 0.0978\n","epoch 74\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.2313 - policy_loss: 2.5084 - value_loss: 0.6479 - policy_categorical_accuracy: 0.3720 - value_mse: 0.0967\n","epoch 75\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.2313 - policy_loss: 2.5105 - value_loss: 0.6459 - policy_categorical_accuracy: 0.3691 - value_mse: 0.0973\n","epoch 76\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.2459 - policy_loss: 2.5272 - value_loss: 0.6438 - policy_categorical_accuracy: 0.3756 - value_mse: 0.0952\n","epoch 77\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.2618 - policy_loss: 2.5429 - value_loss: 0.6440 - policy_categorical_accuracy: 0.3629 - value_mse: 0.0968\n","epoch 78\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.2207 - policy_loss: 2.5022 - value_loss: 0.6436 - policy_categorical_accuracy: 0.3774 - value_mse: 0.0968\n","epoch 79\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.2695 - policy_loss: 2.5535 - value_loss: 0.6411 - policy_categorical_accuracy: 0.3752 - value_mse: 0.0952\n","epoch 80\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.2746 - policy_loss: 2.5470 - value_loss: 0.6526 - policy_categorical_accuracy: 0.3656 - value_mse: 0.1011\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.8892836570739746, 3.1351447105407715, 0.6792510151863098, 0.3107999861240387, 0.11305037885904312]\n","epoch 81\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.3603 - policy_loss: 2.6307 - value_loss: 0.6547 - policy_categorical_accuracy: 0.3505 - value_mse: 0.1008\n","epoch 82\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.3878 - policy_loss: 2.6571 - value_loss: 0.6558 - policy_categorical_accuracy: 0.3505 - value_mse: 0.1008\n","epoch 83\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.3648 - policy_loss: 2.6347 - value_loss: 0.6552 - policy_categorical_accuracy: 0.3510 - value_mse: 0.1020\n","epoch 84\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.3579 - policy_loss: 2.6278 - value_loss: 0.6553 - policy_categorical_accuracy: 0.3545 - value_mse: 0.1007\n","epoch 85\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.3258 - policy_loss: 2.5950 - value_loss: 0.6560 - policy_categorical_accuracy: 0.3615 - value_mse: 0.1013\n","epoch 86\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.3128 - policy_loss: 2.5854 - value_loss: 0.6526 - policy_categorical_accuracy: 0.3629 - value_mse: 0.1011\n","epoch 87\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 136ms/step - loss: 3.3131 - policy_loss: 2.5854 - value_loss: 0.6528 - policy_categorical_accuracy: 0.3624 - value_mse: 0.1016\n","epoch 88\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.3014 - policy_loss: 2.5705 - value_loss: 0.6561 - policy_categorical_accuracy: 0.3605 - value_mse: 0.1035\n","epoch 89\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.3672 - policy_loss: 2.6412 - value_loss: 0.6512 - policy_categorical_accuracy: 0.3551 - value_mse: 0.1005\n","epoch 90\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.2936 - policy_loss: 2.5695 - value_loss: 0.6494 - policy_categorical_accuracy: 0.3612 - value_mse: 0.1008\n","epoch 91\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.3485 - policy_loss: 2.6199 - value_loss: 0.6539 - policy_categorical_accuracy: 0.3543 - value_mse: 0.1020\n","epoch 92\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.3338 - policy_loss: 2.6023 - value_loss: 0.6569 - policy_categorical_accuracy: 0.3601 - value_mse: 0.1019\n","epoch 93\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.2861 - policy_loss: 2.5605 - value_loss: 0.6510 - policy_categorical_accuracy: 0.3729 - value_mse: 0.0999\n","epoch 94\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.3041 - policy_loss: 2.5802 - value_loss: 0.6493 - policy_categorical_accuracy: 0.3552 - value_mse: 0.1002\n","epoch 95\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.3185 - policy_loss: 2.5892 - value_loss: 0.6548 - policy_categorical_accuracy: 0.3584 - value_mse: 0.1017\n","epoch 96\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.3053 - policy_loss: 2.5803 - value_loss: 0.6505 - policy_categorical_accuracy: 0.3621 - value_mse: 0.0996\n","epoch 97\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 136ms/step - loss: 3.2788 - policy_loss: 2.5509 - value_loss: 0.6534 - policy_categorical_accuracy: 0.3685 - value_mse: 0.1014\n","epoch 98\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.3013 - policy_loss: 2.5782 - value_loss: 0.6486 - policy_categorical_accuracy: 0.3632 - value_mse: 0.1002\n","epoch 99\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.2816 - policy_loss: 2.5574 - value_loss: 0.6498 - policy_categorical_accuracy: 0.3675 - value_mse: 0.1000\n","epoch 100\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.2783 - policy_loss: 2.5532 - value_loss: 0.6508 - policy_categorical_accuracy: 0.3669 - value_mse: 0.1001\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.4804975986480713, 2.6173973083496094, 0.7887510061264038, 0.35100001096725464, 0.15201671421527863]\n","epoch 101\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.2654 - policy_loss: 2.5419 - value_loss: 0.6492 - policy_categorical_accuracy: 0.3673 - value_mse: 0.0991\n","epoch 102\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.2638 - policy_loss: 2.5375 - value_loss: 0.6520 - policy_categorical_accuracy: 0.3724 - value_mse: 0.0993\n","epoch 103\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.2357 - policy_loss: 2.5099 - value_loss: 0.6516 - policy_categorical_accuracy: 0.3712 - value_mse: 0.1004\n","epoch 104\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.2405 - policy_loss: 2.5184 - value_loss: 0.6480 - policy_categorical_accuracy: 0.3678 - value_mse: 0.0983\n","epoch 105\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 132ms/step - loss: 3.2682 - policy_loss: 2.5428 - value_loss: 0.6513 - policy_categorical_accuracy: 0.3648 - value_mse: 0.1000\n","epoch 106\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.2615 - policy_loss: 2.5377 - value_loss: 0.6498 - policy_categorical_accuracy: 0.3714 - value_mse: 0.0992\n","epoch 107\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.2454 - policy_loss: 2.5210 - value_loss: 0.6503 - policy_categorical_accuracy: 0.3681 - value_mse: 0.1017\n","epoch 108\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.2326 - policy_loss: 2.5080 - value_loss: 0.6506 - policy_categorical_accuracy: 0.3742 - value_mse: 0.1006\n","epoch 109\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.2694 - policy_loss: 2.5470 - value_loss: 0.6484 - policy_categorical_accuracy: 0.3646 - value_mse: 0.0999\n","epoch 110\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.2094 - policy_loss: 2.4869 - value_loss: 0.6485 - policy_categorical_accuracy: 0.3722 - value_mse: 0.0990\n","epoch 111\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.2424 - policy_loss: 2.5193 - value_loss: 0.6492 - policy_categorical_accuracy: 0.3736 - value_mse: 0.0965\n","epoch 112\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.2173 - policy_loss: 2.4993 - value_loss: 0.6441 - policy_categorical_accuracy: 0.3740 - value_mse: 0.0977\n","epoch 113\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.2035 - policy_loss: 2.4886 - value_loss: 0.6411 - policy_categorical_accuracy: 0.3683 - value_mse: 0.0966\n","epoch 114\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.2143 - policy_loss: 2.4926 - value_loss: 0.6479 - policy_categorical_accuracy: 0.3720 - value_mse: 0.0979\n","epoch 115\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.2244 - policy_loss: 2.5043 - value_loss: 0.6464 - policy_categorical_accuracy: 0.3700 - value_mse: 0.0964\n","epoch 116\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.1657 - policy_loss: 2.4472 - value_loss: 0.6448 - policy_categorical_accuracy: 0.3812 - value_mse: 0.0984\n","epoch 117\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.2075 - policy_loss: 2.4903 - value_loss: 0.6436 - policy_categorical_accuracy: 0.3779 - value_mse: 0.0978\n","epoch 118\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.2185 - policy_loss: 2.4989 - value_loss: 0.6461 - policy_categorical_accuracy: 0.3738 - value_mse: 0.0968\n","epoch 119\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1993 - policy_loss: 2.4852 - value_loss: 0.6407 - policy_categorical_accuracy: 0.3725 - value_mse: 0.0933\n","epoch 120\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1641 - policy_loss: 2.4480 - value_loss: 0.6427 - policy_categorical_accuracy: 0.3775 - value_mse: 0.0958\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.336832046508789, 2.5816493034362793, 0.681787371635437, 0.3668999969959259, 0.11164479702711105]\n","epoch 121\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.2023 - policy_loss: 2.4833 - value_loss: 0.6456 - policy_categorical_accuracy: 0.3795 - value_mse: 0.0974\n","epoch 122\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1692 - policy_loss: 2.4499 - value_loss: 0.6460 - policy_categorical_accuracy: 0.3816 - value_mse: 0.0970\n","epoch 123\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 132ms/step - loss: 3.1718 - policy_loss: 2.4577 - value_loss: 0.6408 - policy_categorical_accuracy: 0.3811 - value_mse: 0.0958\n","epoch 124\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.1899 - policy_loss: 2.4738 - value_loss: 0.6429 - policy_categorical_accuracy: 0.3741 - value_mse: 0.0963\n","epoch 125\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.1455 - policy_loss: 2.4319 - value_loss: 0.6405 - policy_categorical_accuracy: 0.3872 - value_mse: 0.0969\n","epoch 126\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1753 - policy_loss: 2.4621 - value_loss: 0.6400 - policy_categorical_accuracy: 0.3795 - value_mse: 0.0961\n","epoch 127\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.1315 - policy_loss: 2.4147 - value_loss: 0.6437 - policy_categorical_accuracy: 0.3855 - value_mse: 0.0958\n","epoch 128\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1408 - policy_loss: 2.4277 - value_loss: 0.6400 - policy_categorical_accuracy: 0.3842 - value_mse: 0.0954\n","epoch 129\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.1521 - policy_loss: 2.4378 - value_loss: 0.6414 - policy_categorical_accuracy: 0.3847 - value_mse: 0.0959\n","epoch 130\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1355 - policy_loss: 2.4247 - value_loss: 0.6379 - policy_categorical_accuracy: 0.3821 - value_mse: 0.0957\n","epoch 131\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.1058 - policy_loss: 2.3946 - value_loss: 0.6382 - policy_categorical_accuracy: 0.3906 - value_mse: 0.0959\n","epoch 132\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1562 - policy_loss: 2.4447 - value_loss: 0.6386 - policy_categorical_accuracy: 0.3828 - value_mse: 0.0953\n","epoch 133\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1431 - policy_loss: 2.4318 - value_loss: 0.6385 - policy_categorical_accuracy: 0.3836 - value_mse: 0.0944\n","epoch 134\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.1341 - policy_loss: 2.4250 - value_loss: 0.6362 - policy_categorical_accuracy: 0.3807 - value_mse: 0.0923\n","epoch 135\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1266 - policy_loss: 2.4178 - value_loss: 0.6360 - policy_categorical_accuracy: 0.3877 - value_mse: 0.0932\n","epoch 136\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.1156 - policy_loss: 2.4065 - value_loss: 0.6364 - policy_categorical_accuracy: 0.3854 - value_mse: 0.0933\n","epoch 137\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.1076 - policy_loss: 2.3975 - value_loss: 0.6374 - policy_categorical_accuracy: 0.3893 - value_mse: 0.0922\n","epoch 138\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1154 - policy_loss: 2.4041 - value_loss: 0.6386 - policy_categorical_accuracy: 0.3855 - value_mse: 0.0943\n","epoch 139\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1138 - policy_loss: 2.4074 - value_loss: 0.6338 - policy_categorical_accuracy: 0.3875 - value_mse: 0.0927\n","epoch 140\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0877 - policy_loss: 2.3804 - value_loss: 0.6347 - policy_categorical_accuracy: 0.3891 - value_mse: 0.0941\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.10371470451355, 2.3869729042053223, 0.6441472172737122, 0.3894999921321869, 0.0975816398859024]\n","epoch 141\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.1138 - policy_loss: 2.4074 - value_loss: 0.6338 - policy_categorical_accuracy: 0.3920 - value_mse: 0.0939\n","epoch 142\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.1125 - policy_loss: 2.4035 - value_loss: 0.6365 - policy_categorical_accuracy: 0.3838 - value_mse: 0.0952\n","epoch 143\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.1047 - policy_loss: 2.3955 - value_loss: 0.6367 - policy_categorical_accuracy: 0.3844 - value_mse: 0.0942\n","epoch 144\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.1093 - policy_loss: 2.3946 - value_loss: 0.6422 - policy_categorical_accuracy: 0.3934 - value_mse: 0.0972\n","epoch 145\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.0869 - policy_loss: 2.3768 - value_loss: 0.6376 - policy_categorical_accuracy: 0.3893 - value_mse: 0.0937\n","epoch 146\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0902 - policy_loss: 2.3847 - value_loss: 0.6330 - policy_categorical_accuracy: 0.3910 - value_mse: 0.0935\n","epoch 147\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1061 - policy_loss: 2.3982 - value_loss: 0.6354 - policy_categorical_accuracy: 0.3939 - value_mse: 0.0947\n","epoch 148\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0640 - policy_loss: 2.3582 - value_loss: 0.6333 - policy_categorical_accuracy: 0.3968 - value_mse: 0.0917\n","epoch 149\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.1130 - policy_loss: 2.4039 - value_loss: 0.6367 - policy_categorical_accuracy: 0.3829 - value_mse: 0.0944\n","epoch 150\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1406 - policy_loss: 2.4325 - value_loss: 0.6357 - policy_categorical_accuracy: 0.3846 - value_mse: 0.0939\n","epoch 151\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0956 - policy_loss: 2.3890 - value_loss: 0.6342 - policy_categorical_accuracy: 0.3939 - value_mse: 0.0919\n","epoch 152\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.1006 - policy_loss: 2.3907 - value_loss: 0.6375 - policy_categorical_accuracy: 0.3925 - value_mse: 0.0944\n","epoch 153\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0655 - policy_loss: 2.3653 - value_loss: 0.6278 - policy_categorical_accuracy: 0.3882 - value_mse: 0.0919\n","epoch 154\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.0873 - policy_loss: 2.3801 - value_loss: 0.6348 - policy_categorical_accuracy: 0.3869 - value_mse: 0.0932\n","epoch 155\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0855 - policy_loss: 2.3814 - value_loss: 0.6317 - policy_categorical_accuracy: 0.3915 - value_mse: 0.0923\n","epoch 156\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.0965 - policy_loss: 2.3862 - value_loss: 0.6380 - policy_categorical_accuracy: 0.3900 - value_mse: 0.0952\n","epoch 157\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0627 - policy_loss: 2.3595 - value_loss: 0.6307 - policy_categorical_accuracy: 0.3892 - value_mse: 0.0911\n","epoch 158\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0884 - policy_loss: 2.3808 - value_loss: 0.6352 - policy_categorical_accuracy: 0.3918 - value_mse: 0.0950\n","epoch 159\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0769 - policy_loss: 2.3712 - value_loss: 0.6333 - policy_categorical_accuracy: 0.3933 - value_mse: 0.0937\n","epoch 160\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0840 - policy_loss: 2.3776 - value_loss: 0.6340 - policy_categorical_accuracy: 0.3971 - value_mse: 0.0919\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.062098741531372, 2.357203483581543, 0.6324888467788696, 0.39419999718666077, 0.09275724738836288]\n","epoch 161\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.1019 - policy_loss: 2.3942 - value_loss: 0.6353 - policy_categorical_accuracy: 0.3959 - value_mse: 0.0931\n","epoch 162\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.2389 - policy_loss: 2.5173 - value_loss: 0.6491 - policy_categorical_accuracy: 0.3728 - value_mse: 0.0996\n","epoch 163\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1990 - policy_loss: 2.4774 - value_loss: 0.6491 - policy_categorical_accuracy: 0.3835 - value_mse: 0.1012\n","epoch 164\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.2476 - policy_loss: 2.5277 - value_loss: 0.6474 - policy_categorical_accuracy: 0.3645 - value_mse: 0.0963\n","epoch 165\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.1890 - policy_loss: 2.4696 - value_loss: 0.6468 - policy_categorical_accuracy: 0.3753 - value_mse: 0.0988\n","epoch 166\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.1585 - policy_loss: 2.4405 - value_loss: 0.6456 - policy_categorical_accuracy: 0.3856 - value_mse: 0.0979\n","epoch 167\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.2124 - policy_loss: 2.4915 - value_loss: 0.6483 - policy_categorical_accuracy: 0.3749 - value_mse: 0.0986\n","epoch 168\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.2179 - policy_loss: 2.5013 - value_loss: 0.6440 - policy_categorical_accuracy: 0.3748 - value_mse: 0.0973\n","epoch 169\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1962 - policy_loss: 2.4731 - value_loss: 0.6506 - policy_categorical_accuracy: 0.3812 - value_mse: 0.0994\n","epoch 170\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.2142 - policy_loss: 2.4913 - value_loss: 0.6503 - policy_categorical_accuracy: 0.3708 - value_mse: 0.0978\n","epoch 171\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1877 - policy_loss: 2.4683 - value_loss: 0.6468 - policy_categorical_accuracy: 0.3782 - value_mse: 0.0976\n","epoch 172\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1820 - policy_loss: 2.4635 - value_loss: 0.6460 - policy_categorical_accuracy: 0.3834 - value_mse: 0.0988\n","epoch 173\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 137ms/step - loss: 3.2147 - policy_loss: 2.4939 - value_loss: 0.6482 - policy_categorical_accuracy: 0.3736 - value_mse: 0.0979\n","epoch 174\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1167 - policy_loss: 2.3992 - value_loss: 0.6450 - policy_categorical_accuracy: 0.3885 - value_mse: 0.0983\n","epoch 175\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1846 - policy_loss: 2.4657 - value_loss: 0.6463 - policy_categorical_accuracy: 0.3795 - value_mse: 0.0995\n","epoch 176\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1855 - policy_loss: 2.4687 - value_loss: 0.6442 - policy_categorical_accuracy: 0.3770 - value_mse: 0.0962\n","epoch 177\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.1939 - policy_loss: 2.4763 - value_loss: 0.6451 - policy_categorical_accuracy: 0.3779 - value_mse: 0.0966\n","epoch 178\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.2141 - policy_loss: 2.4958 - value_loss: 0.6458 - policy_categorical_accuracy: 0.3725 - value_mse: 0.0970\n","epoch 179\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.2009 - policy_loss: 2.4862 - value_loss: 0.6421 - policy_categorical_accuracy: 0.3765 - value_mse: 0.0965\n","epoch 180\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1738 - policy_loss: 2.4573 - value_loss: 0.6440 - policy_categorical_accuracy: 0.3797 - value_mse: 0.0981\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.3922243118286133, 2.6033775806427, 0.7163301110267639, 0.36239999532699585, 0.12752895057201385]\n","epoch 181\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.1647 - policy_loss: 2.4491 - value_loss: 0.6430 - policy_categorical_accuracy: 0.3839 - value_mse: 0.0962\n","epoch 182\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 136ms/step - loss: 3.1923 - policy_loss: 2.4786 - value_loss: 0.6411 - policy_categorical_accuracy: 0.3708 - value_mse: 0.0972\n","epoch 183\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.1645 - policy_loss: 2.4423 - value_loss: 0.6497 - policy_categorical_accuracy: 0.3908 - value_mse: 0.0998\n","epoch 184\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1741 - policy_loss: 2.4591 - value_loss: 0.6425 - policy_categorical_accuracy: 0.3787 - value_mse: 0.0964\n","epoch 185\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1650 - policy_loss: 2.4467 - value_loss: 0.6458 - policy_categorical_accuracy: 0.3830 - value_mse: 0.0983\n","epoch 186\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1521 - policy_loss: 2.4388 - value_loss: 0.6408 - policy_categorical_accuracy: 0.3851 - value_mse: 0.0955\n","epoch 187\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1739 - policy_loss: 2.4561 - value_loss: 0.6453 - policy_categorical_accuracy: 0.3753 - value_mse: 0.0980\n","epoch 188\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.1350 - policy_loss: 2.4211 - value_loss: 0.6414 - policy_categorical_accuracy: 0.3855 - value_mse: 0.0952\n","epoch 189\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1544 - policy_loss: 2.4411 - value_loss: 0.6409 - policy_categorical_accuracy: 0.3825 - value_mse: 0.0975\n","epoch 190\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.1339 - policy_loss: 2.4153 - value_loss: 0.6461 - policy_categorical_accuracy: 0.3865 - value_mse: 0.0999\n","epoch 191\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1608 - policy_loss: 2.4486 - value_loss: 0.6398 - policy_categorical_accuracy: 0.3738 - value_mse: 0.0957\n","epoch 192\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1492 - policy_loss: 2.4323 - value_loss: 0.6445 - policy_categorical_accuracy: 0.3817 - value_mse: 0.0959\n","epoch 193\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1362 - policy_loss: 2.4222 - value_loss: 0.6416 - policy_categorical_accuracy: 0.3849 - value_mse: 0.0961\n","epoch 194\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1667 - policy_loss: 2.4585 - value_loss: 0.6358 - policy_categorical_accuracy: 0.3777 - value_mse: 0.0942\n","epoch 195\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1445 - policy_loss: 2.4266 - value_loss: 0.6456 - policy_categorical_accuracy: 0.3854 - value_mse: 0.0991\n","epoch 196\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 132ms/step - loss: 3.1337 - policy_loss: 2.4205 - value_loss: 0.6408 - policy_categorical_accuracy: 0.3806 - value_mse: 0.0947\n","epoch 197\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1099 - policy_loss: 2.3941 - value_loss: 0.6436 - policy_categorical_accuracy: 0.3842 - value_mse: 0.0961\n","epoch 198\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 132ms/step - loss: 3.1393 - policy_loss: 2.4276 - value_loss: 0.6393 - policy_categorical_accuracy: 0.3820 - value_mse: 0.0937\n","epoch 199\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.1473 - policy_loss: 2.4314 - value_loss: 0.6436 - policy_categorical_accuracy: 0.3828 - value_mse: 0.0990\n","epoch 200\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 132ms/step - loss: 3.1610 - policy_loss: 2.4455 - value_loss: 0.6433 - policy_categorical_accuracy: 0.3775 - value_mse: 0.0953\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.322833299636841, 2.5247228145599365, 0.7258669137954712, 0.37689998745918274, 0.1300605833530426]\n","epoch 201\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.1176 - policy_loss: 2.4025 - value_loss: 0.6428 - policy_categorical_accuracy: 0.3898 - value_mse: 0.0952\n","epoch 202\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.1087 - policy_loss: 2.3958 - value_loss: 0.6406 - policy_categorical_accuracy: 0.3919 - value_mse: 0.0961\n","epoch 203\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 136ms/step - loss: 3.1164 - policy_loss: 2.4057 - value_loss: 0.6385 - policy_categorical_accuracy: 0.3846 - value_mse: 0.0958\n","epoch 204\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.1148 - policy_loss: 2.3985 - value_loss: 0.6442 - policy_categorical_accuracy: 0.3907 - value_mse: 0.0980\n","epoch 205\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.1296 - policy_loss: 2.4139 - value_loss: 0.6435 - policy_categorical_accuracy: 0.3868 - value_mse: 0.0949\n","epoch 206\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1206 - policy_loss: 2.4100 - value_loss: 0.6385 - policy_categorical_accuracy: 0.3816 - value_mse: 0.0925\n","epoch 207\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.1080 - policy_loss: 2.3997 - value_loss: 0.6361 - policy_categorical_accuracy: 0.3902 - value_mse: 0.0956\n","epoch 208\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.1393 - policy_loss: 2.4275 - value_loss: 0.6397 - policy_categorical_accuracy: 0.3853 - value_mse: 0.0934\n","epoch 209\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0966 - policy_loss: 2.3867 - value_loss: 0.6378 - policy_categorical_accuracy: 0.3894 - value_mse: 0.0967\n","epoch 210\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1226 - policy_loss: 2.4105 - value_loss: 0.6400 - policy_categorical_accuracy: 0.3883 - value_mse: 0.0960\n","epoch 211\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0737 - policy_loss: 2.3643 - value_loss: 0.6374 - policy_categorical_accuracy: 0.3952 - value_mse: 0.0953\n","epoch 212\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.0929 - policy_loss: 2.3819 - value_loss: 0.6390 - policy_categorical_accuracy: 0.3936 - value_mse: 0.0947\n","epoch 213\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0998 - policy_loss: 2.3899 - value_loss: 0.6380 - policy_categorical_accuracy: 0.3899 - value_mse: 0.0975\n","epoch 214\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1043 - policy_loss: 2.3928 - value_loss: 0.6396 - policy_categorical_accuracy: 0.3871 - value_mse: 0.0942\n","epoch 215\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1090 - policy_loss: 2.3962 - value_loss: 0.6409 - policy_categorical_accuracy: 0.3867 - value_mse: 0.0946\n","epoch 216\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.0751 - policy_loss: 2.3656 - value_loss: 0.6377 - policy_categorical_accuracy: 0.3896 - value_mse: 0.0946\n","epoch 217\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.0785 - policy_loss: 2.3677 - value_loss: 0.6389 - policy_categorical_accuracy: 0.3933 - value_mse: 0.0945\n","epoch 218\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1030 - policy_loss: 2.3951 - value_loss: 0.6361 - policy_categorical_accuracy: 0.3847 - value_mse: 0.0938\n","epoch 219\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0874 - policy_loss: 2.3780 - value_loss: 0.6376 - policy_categorical_accuracy: 0.3950 - value_mse: 0.0937\n","epoch 220\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 132ms/step - loss: 3.0635 - policy_loss: 2.3578 - value_loss: 0.6338 - policy_categorical_accuracy: 0.3911 - value_mse: 0.0936\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.355769634246826, 2.5655205249786377, 0.7184749841690063, 0.3734999895095825, 0.12425700575113297]\n","epoch 221\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 132ms/step - loss: 3.0967 - policy_loss: 2.3915 - value_loss: 0.6334 - policy_categorical_accuracy: 0.3891 - value_mse: 0.0925\n","epoch 222\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0668 - policy_loss: 2.3601 - value_loss: 0.6350 - policy_categorical_accuracy: 0.3942 - value_mse: 0.0919\n","epoch 223\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.1163 - policy_loss: 2.4120 - value_loss: 0.6326 - policy_categorical_accuracy: 0.3808 - value_mse: 0.0930\n","epoch 224\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 136ms/step - loss: 3.0578 - policy_loss: 2.3502 - value_loss: 0.6360 - policy_categorical_accuracy: 0.3939 - value_mse: 0.0946\n","epoch 225\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.0480 - policy_loss: 2.3371 - value_loss: 0.6393 - policy_categorical_accuracy: 0.4026 - value_mse: 0.0948\n","epoch 226\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0571 - policy_loss: 2.3475 - value_loss: 0.6380 - policy_categorical_accuracy: 0.3957 - value_mse: 0.0956\n","epoch 227\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.0763 - policy_loss: 2.3663 - value_loss: 0.6385 - policy_categorical_accuracy: 0.3905 - value_mse: 0.0957\n","epoch 228\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0904 - policy_loss: 2.3860 - value_loss: 0.6329 - policy_categorical_accuracy: 0.3889 - value_mse: 0.0920\n","epoch 229\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0642 - policy_loss: 2.3611 - value_loss: 0.6316 - policy_categorical_accuracy: 0.3961 - value_mse: 0.0916\n","epoch 230\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0523 - policy_loss: 2.3451 - value_loss: 0.6357 - policy_categorical_accuracy: 0.4000 - value_mse: 0.0929\n","epoch 231\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0652 - policy_loss: 2.3561 - value_loss: 0.6377 - policy_categorical_accuracy: 0.3942 - value_mse: 0.0926\n","epoch 232\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0802 - policy_loss: 2.3784 - value_loss: 0.6305 - policy_categorical_accuracy: 0.3876 - value_mse: 0.0914\n","epoch 233\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.1051 - policy_loss: 2.4019 - value_loss: 0.6319 - policy_categorical_accuracy: 0.3822 - value_mse: 0.0917\n","epoch 234\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 137ms/step - loss: 3.0642 - policy_loss: 2.3601 - value_loss: 0.6328 - policy_categorical_accuracy: 0.3966 - value_mse: 0.0911\n","epoch 235\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0260 - policy_loss: 2.3174 - value_loss: 0.6373 - policy_categorical_accuracy: 0.4019 - value_mse: 0.0924\n","epoch 236\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0505 - policy_loss: 2.3453 - value_loss: 0.6340 - policy_categorical_accuracy: 0.3948 - value_mse: 0.0928\n","epoch 237\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0800 - policy_loss: 2.3717 - value_loss: 0.6372 - policy_categorical_accuracy: 0.3949 - value_mse: 0.0940\n","epoch 238\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0313 - policy_loss: 2.3256 - value_loss: 0.6346 - policy_categorical_accuracy: 0.3965 - value_mse: 0.0925\n","epoch 239\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.0449 - policy_loss: 2.3420 - value_loss: 0.6319 - policy_categorical_accuracy: 0.4011 - value_mse: 0.0922\n","epoch 240\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0548 - policy_loss: 2.3523 - value_loss: 0.6315 - policy_categorical_accuracy: 0.3977 - value_mse: 0.0924\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.135758399963379, 2.389831304550171, 0.6748577952384949, 0.3864000141620636, 0.10917682945728302]\n","epoch 241\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0369 - policy_loss: 2.3361 - value_loss: 0.6298 - policy_categorical_accuracy: 0.3930 - value_mse: 0.0903\n","epoch 242\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.0430 - policy_loss: 2.3400 - value_loss: 0.6320 - policy_categorical_accuracy: 0.3939 - value_mse: 0.0921\n","epoch 243\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0472 - policy_loss: 2.3422 - value_loss: 0.6340 - policy_categorical_accuracy: 0.4015 - value_mse: 0.0932\n","epoch 244\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0473 - policy_loss: 2.3468 - value_loss: 0.6296 - policy_categorical_accuracy: 0.3934 - value_mse: 0.0914\n","epoch 245\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0495 - policy_loss: 2.3478 - value_loss: 0.6308 - policy_categorical_accuracy: 0.3936 - value_mse: 0.0916\n","epoch 246\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0487 - policy_loss: 2.3497 - value_loss: 0.6281 - policy_categorical_accuracy: 0.3904 - value_mse: 0.0890\n","epoch 247\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0388 - policy_loss: 2.3376 - value_loss: 0.6304 - policy_categorical_accuracy: 0.3965 - value_mse: 0.0916\n","epoch 248\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 132ms/step - loss: 2.9921 - policy_loss: 2.2896 - value_loss: 0.6317 - policy_categorical_accuracy: 0.4071 - value_mse: 0.0918\n","epoch 249\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 132ms/step - loss: 2.9996 - policy_loss: 2.2990 - value_loss: 0.6298 - policy_categorical_accuracy: 0.4028 - value_mse: 0.0907\n","epoch 250\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0215 - policy_loss: 2.3216 - value_loss: 0.6292 - policy_categorical_accuracy: 0.4017 - value_mse: 0.0918\n","epoch 251\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0144 - policy_loss: 2.3106 - value_loss: 0.6331 - policy_categorical_accuracy: 0.4037 - value_mse: 0.0914\n","epoch 252\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0006 - policy_loss: 2.3028 - value_loss: 0.6271 - policy_categorical_accuracy: 0.3999 - value_mse: 0.0894\n","epoch 253\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0006 - policy_loss: 2.3039 - value_loss: 0.6260 - policy_categorical_accuracy: 0.3994 - value_mse: 0.0918\n","epoch 254\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0235 - policy_loss: 2.3267 - value_loss: 0.6263 - policy_categorical_accuracy: 0.3963 - value_mse: 0.0900\n","epoch 255\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0179 - policy_loss: 2.3212 - value_loss: 0.6262 - policy_categorical_accuracy: 0.4011 - value_mse: 0.0909\n","epoch 256\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.0122 - policy_loss: 2.3121 - value_loss: 0.6297 - policy_categorical_accuracy: 0.4001 - value_mse: 0.0907\n","epoch 257\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0111 - policy_loss: 2.3090 - value_loss: 0.6317 - policy_categorical_accuracy: 0.4037 - value_mse: 0.0931\n","epoch 258\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0118 - policy_loss: 2.3096 - value_loss: 0.6318 - policy_categorical_accuracy: 0.3978 - value_mse: 0.0900\n","epoch 259\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0241 - policy_loss: 2.3273 - value_loss: 0.6264 - policy_categorical_accuracy: 0.4051 - value_mse: 0.0886\n","epoch 260\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0470 - policy_loss: 2.3496 - value_loss: 0.6270 - policy_categorical_accuracy: 0.3876 - value_mse: 0.0907\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.031097888946533, 2.3283207416534424, 0.6324405670166016, 0.4034999907016754, 0.09333720803260803]\n","epoch 261\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9916 - policy_loss: 2.2928 - value_loss: 0.6286 - policy_categorical_accuracy: 0.4007 - value_mse: 0.0918\n","epoch 262\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 2.9895 - policy_loss: 2.2900 - value_loss: 0.6292 - policy_categorical_accuracy: 0.4036 - value_mse: 0.0906\n","epoch 263\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0173 - policy_loss: 2.3178 - value_loss: 0.6292 - policy_categorical_accuracy: 0.3973 - value_mse: 0.0909\n","epoch 264\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 2.9788 - policy_loss: 2.2815 - value_loss: 0.6271 - policy_categorical_accuracy: 0.4083 - value_mse: 0.0893\n","epoch 265\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.0017 - policy_loss: 2.3037 - value_loss: 0.6278 - policy_categorical_accuracy: 0.4034 - value_mse: 0.0909\n","epoch 266\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 2.9809 - policy_loss: 2.2870 - value_loss: 0.6238 - policy_categorical_accuracy: 0.4016 - value_mse: 0.0884\n","epoch 267\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 136ms/step - loss: 2.9559 - policy_loss: 2.2609 - value_loss: 0.6249 - policy_categorical_accuracy: 0.4115 - value_mse: 0.0901\n","epoch 268\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9654 - policy_loss: 2.2670 - value_loss: 0.6283 - policy_categorical_accuracy: 0.4105 - value_mse: 0.0896\n","epoch 269\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9957 - policy_loss: 2.2969 - value_loss: 0.6288 - policy_categorical_accuracy: 0.4036 - value_mse: 0.0894\n","epoch 270\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 2.9869 - policy_loss: 2.2858 - value_loss: 0.6311 - policy_categorical_accuracy: 0.4076 - value_mse: 0.0901\n","epoch 271\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 2.9799 - policy_loss: 2.2847 - value_loss: 0.6253 - policy_categorical_accuracy: 0.4069 - value_mse: 0.0895\n","epoch 272\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 2.9510 - policy_loss: 2.2596 - value_loss: 0.6215 - policy_categorical_accuracy: 0.4119 - value_mse: 0.0871\n","epoch 273\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0045 - policy_loss: 2.3091 - value_loss: 0.6255 - policy_categorical_accuracy: 0.4003 - value_mse: 0.0897\n","epoch 274\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 132ms/step - loss: 2.9775 - policy_loss: 2.2840 - value_loss: 0.6236 - policy_categorical_accuracy: 0.4049 - value_mse: 0.0892\n","epoch 275\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 2.9883 - policy_loss: 2.2970 - value_loss: 0.6215 - policy_categorical_accuracy: 0.3950 - value_mse: 0.0888\n","epoch 276\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 2.9655 - policy_loss: 2.2736 - value_loss: 0.6221 - policy_categorical_accuracy: 0.4059 - value_mse: 0.0887\n","epoch 277\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 2.9884 - policy_loss: 2.2950 - value_loss: 0.6236 - policy_categorical_accuracy: 0.4024 - value_mse: 0.0880\n","epoch 278\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.0025 - policy_loss: 2.3071 - value_loss: 0.6256 - policy_categorical_accuracy: 0.4013 - value_mse: 0.0880\n","epoch 279\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9940 - policy_loss: 2.3005 - value_loss: 0.6237 - policy_categorical_accuracy: 0.4034 - value_mse: 0.0880\n","epoch 280\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 137ms/step - loss: 2.9368 - policy_loss: 2.2486 - value_loss: 0.6184 - policy_categorical_accuracy: 0.4138 - value_mse: 0.0870\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9659483432769775, 2.260406732559204, 0.6358011960983276, 0.4104999899864197, 0.0945005863904953]\n","epoch 281\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9307 - policy_loss: 2.2372 - value_loss: 0.6238 - policy_categorical_accuracy: 0.4159 - value_mse: 0.0892\n","epoch 282\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9832 - policy_loss: 2.2894 - value_loss: 0.6241 - policy_categorical_accuracy: 0.4045 - value_mse: 0.0890\n","epoch 283\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9886 - policy_loss: 2.2928 - value_loss: 0.6261 - policy_categorical_accuracy: 0.4009 - value_mse: 0.0891\n","epoch 284\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9913 - policy_loss: 2.2950 - value_loss: 0.6267 - policy_categorical_accuracy: 0.4054 - value_mse: 0.0889\n","epoch 285\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 2.9856 - policy_loss: 2.2931 - value_loss: 0.6229 - policy_categorical_accuracy: 0.3985 - value_mse: 0.0895\n","epoch 286\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 2.9287 - policy_loss: 2.2382 - value_loss: 0.6208 - policy_categorical_accuracy: 0.4209 - value_mse: 0.0870\n","epoch 287\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 2.9396 - policy_loss: 2.2465 - value_loss: 0.6235 - policy_categorical_accuracy: 0.4096 - value_mse: 0.0880\n","epoch 288\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 2.9668 - policy_loss: 2.2736 - value_loss: 0.6236 - policy_categorical_accuracy: 0.4068 - value_mse: 0.0879\n","epoch 289\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9653 - policy_loss: 2.2757 - value_loss: 0.6200 - policy_categorical_accuracy: 0.4089 - value_mse: 0.0851\n","epoch 290\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 2.9669 - policy_loss: 2.2773 - value_loss: 0.6201 - policy_categorical_accuracy: 0.4031 - value_mse: 0.0877\n","epoch 291\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9754 - policy_loss: 2.2857 - value_loss: 0.6202 - policy_categorical_accuracy: 0.4050 - value_mse: 0.0870\n","epoch 292\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 2.9820 - policy_loss: 2.2875 - value_loss: 0.6249 - policy_categorical_accuracy: 0.4057 - value_mse: 0.0898\n","epoch 293\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 2.9557 - policy_loss: 2.2686 - value_loss: 0.6176 - policy_categorical_accuracy: 0.4061 - value_mse: 0.0874\n","epoch 294\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 2.9771 - policy_loss: 2.2851 - value_loss: 0.6225 - policy_categorical_accuracy: 0.4022 - value_mse: 0.0862\n","epoch 295\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 2.9337 - policy_loss: 2.2435 - value_loss: 0.6207 - policy_categorical_accuracy: 0.4148 - value_mse: 0.0870\n","epoch 296\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 2.9600 - policy_loss: 2.2682 - value_loss: 0.6224 - policy_categorical_accuracy: 0.4091 - value_mse: 0.0883\n","epoch 297\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9672 - policy_loss: 2.2786 - value_loss: 0.6192 - policy_categorical_accuracy: 0.4038 - value_mse: 0.0864\n","epoch 298\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9514 - policy_loss: 2.2614 - value_loss: 0.6205 - policy_categorical_accuracy: 0.4053 - value_mse: 0.0897\n","epoch 299\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 2.9444 - policy_loss: 2.2538 - value_loss: 0.6212 - policy_categorical_accuracy: 0.4051 - value_mse: 0.0877\n","epoch 300\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9618 - policy_loss: 2.2740 - value_loss: 0.6183 - policy_categorical_accuracy: 0.4047 - value_mse: 0.0870\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9224774837493896, 2.2341301441192627, 0.6189213991165161, 0.41350001096725464, 0.08748909085988998]\n","epoch 301\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9650 - policy_loss: 2.2744 - value_loss: 0.6211 - policy_categorical_accuracy: 0.4015 - value_mse: 0.0878\n","epoch 302\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 2.9294 - policy_loss: 2.2368 - value_loss: 0.6232 - policy_categorical_accuracy: 0.4146 - value_mse: 0.0893\n","epoch 303\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 132ms/step - loss: 2.9504 - policy_loss: 2.2595 - value_loss: 0.6214 - policy_categorical_accuracy: 0.4111 - value_mse: 0.0875\n","epoch 304\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 2.9526 - policy_loss: 2.2599 - value_loss: 0.6233 - policy_categorical_accuracy: 0.4085 - value_mse: 0.0888\n","epoch 305\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 2.9581 - policy_loss: 2.2701 - value_loss: 0.6186 - policy_categorical_accuracy: 0.4048 - value_mse: 0.0862\n","epoch 306\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 2.9249 - policy_loss: 2.2341 - value_loss: 0.6214 - policy_categorical_accuracy: 0.4098 - value_mse: 0.0869\n","epoch 307\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 132ms/step - loss: 2.9435 - policy_loss: 2.2635 - value_loss: 0.6106 - policy_categorical_accuracy: 0.4055 - value_mse: 0.0856\n","epoch 308\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 2.9787 - policy_loss: 2.2890 - value_loss: 0.6202 - policy_categorical_accuracy: 0.4033 - value_mse: 0.0879\n","epoch 309\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9538 - policy_loss: 2.2707 - value_loss: 0.6137 - policy_categorical_accuracy: 0.4051 - value_mse: 0.0862\n","epoch 310\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 2.9285 - policy_loss: 2.2389 - value_loss: 0.6202 - policy_categorical_accuracy: 0.4162 - value_mse: 0.0866\n","epoch 311\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9440 - policy_loss: 2.2518 - value_loss: 0.6229 - policy_categorical_accuracy: 0.4061 - value_mse: 0.0876\n","epoch 312\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 2.9355 - policy_loss: 2.2459 - value_loss: 0.6203 - policy_categorical_accuracy: 0.4108 - value_mse: 0.0877\n","epoch 313\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9354 - policy_loss: 2.2518 - value_loss: 0.6143 - policy_categorical_accuracy: 0.4078 - value_mse: 0.0864\n","epoch 314\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 2.9626 - policy_loss: 2.2773 - value_loss: 0.6159 - policy_categorical_accuracy: 0.4039 - value_mse: 0.0862\n","epoch 315\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9356 - policy_loss: 2.2512 - value_loss: 0.6151 - policy_categorical_accuracy: 0.4071 - value_mse: 0.0862\n","epoch 316\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 2.9613 - policy_loss: 2.2672 - value_loss: 0.6248 - policy_categorical_accuracy: 0.4058 - value_mse: 0.0872\n","epoch 317\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 2.9455 - policy_loss: 2.2598 - value_loss: 0.6164 - policy_categorical_accuracy: 0.4075 - value_mse: 0.0861\n","epoch 318\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 2.9730 - policy_loss: 2.2832 - value_loss: 0.6204 - policy_categorical_accuracy: 0.4052 - value_mse: 0.0880\n","epoch 319\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9796 - policy_loss: 2.2892 - value_loss: 0.6210 - policy_categorical_accuracy: 0.4085 - value_mse: 0.0883\n","epoch 320\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 132ms/step - loss: 2.9429 - policy_loss: 2.2527 - value_loss: 0.6208 - policy_categorical_accuracy: 0.4049 - value_mse: 0.0868\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [2.9160172939300537, 2.2283871173858643, 0.618270754814148, 0.41359999775886536, 0.08724305778741837]\n","epoch 321\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9171 - policy_loss: 2.2296 - value_loss: 0.6181 - policy_categorical_accuracy: 0.4133 - value_mse: 0.0855\n","epoch 322\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9299 - policy_loss: 2.2432 - value_loss: 0.6173 - policy_categorical_accuracy: 0.4087 - value_mse: 0.0851\n","epoch 323\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 2.9848 - policy_loss: 2.2888 - value_loss: 0.6266 - policy_categorical_accuracy: 0.4010 - value_mse: 0.0882\n","epoch 324\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0723 - policy_loss: 2.3603 - value_loss: 0.6426 - policy_categorical_accuracy: 0.3879 - value_mse: 0.0966\n","epoch 325\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 136ms/step - loss: 3.0925 - policy_loss: 2.3812 - value_loss: 0.6418 - policy_categorical_accuracy: 0.3873 - value_mse: 0.0952\n","epoch 326\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.0860 - policy_loss: 2.3761 - value_loss: 0.6403 - policy_categorical_accuracy: 0.3904 - value_mse: 0.0950\n","epoch 327\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.0644 - policy_loss: 2.3579 - value_loss: 0.6368 - policy_categorical_accuracy: 0.3954 - value_mse: 0.0953\n","epoch 328\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.0728 - policy_loss: 2.3622 - value_loss: 0.6409 - policy_categorical_accuracy: 0.3939 - value_mse: 0.0953\n","epoch 329\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.1061 - policy_loss: 2.4006 - value_loss: 0.6358 - policy_categorical_accuracy: 0.3809 - value_mse: 0.0931\n","epoch 330\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.1018 - policy_loss: 2.3907 - value_loss: 0.6413 - policy_categorical_accuracy: 0.3866 - value_mse: 0.0935\n","epoch 331\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0936 - policy_loss: 2.3874 - value_loss: 0.6363 - policy_categorical_accuracy: 0.3855 - value_mse: 0.0930\n","epoch 332\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0693 - policy_loss: 2.3617 - value_loss: 0.6377 - policy_categorical_accuracy: 0.3909 - value_mse: 0.0936\n","epoch 333\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0651 - policy_loss: 2.3615 - value_loss: 0.6336 - policy_categorical_accuracy: 0.3929 - value_mse: 0.0929\n","epoch 334\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0827 - policy_loss: 2.3734 - value_loss: 0.6393 - policy_categorical_accuracy: 0.3898 - value_mse: 0.0943\n","epoch 335\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0743 - policy_loss: 2.3679 - value_loss: 0.6364 - policy_categorical_accuracy: 0.3933 - value_mse: 0.0946\n","epoch 336\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0722 - policy_loss: 2.3615 - value_loss: 0.6407 - policy_categorical_accuracy: 0.3904 - value_mse: 0.0985\n","epoch 337\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0536 - policy_loss: 2.3565 - value_loss: 0.6270 - policy_categorical_accuracy: 0.3939 - value_mse: 0.0920\n","epoch 338\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.0781 - policy_loss: 2.3713 - value_loss: 0.6367 - policy_categorical_accuracy: 0.3940 - value_mse: 0.0953\n","epoch 339\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.0522 - policy_loss: 2.3474 - value_loss: 0.6346 - policy_categorical_accuracy: 0.3992 - value_mse: 0.0918\n","epoch 340\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.0738 - policy_loss: 2.3686 - value_loss: 0.6350 - policy_categorical_accuracy: 0.3970 - value_mse: 0.0924\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.295952796936035, 2.514805316925049, 0.7108733057975769, 0.37770000100135803, 0.12327103316783905]\n","epoch 341\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0514 - policy_loss: 2.3401 - value_loss: 0.6411 - policy_categorical_accuracy: 0.3976 - value_mse: 0.0951\n","epoch 342\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.0928 - policy_loss: 2.3908 - value_loss: 0.6317 - policy_categorical_accuracy: 0.3841 - value_mse: 0.0932\n","epoch 343\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0582 - policy_loss: 2.3514 - value_loss: 0.6364 - policy_categorical_accuracy: 0.3914 - value_mse: 0.0922\n","epoch 344\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.0699 - policy_loss: 2.3640 - value_loss: 0.6354 - policy_categorical_accuracy: 0.3888 - value_mse: 0.0927\n","epoch 345\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0420 - policy_loss: 2.3380 - value_loss: 0.6336 - policy_categorical_accuracy: 0.3934 - value_mse: 0.0920\n","epoch 346\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0491 - policy_loss: 2.3421 - value_loss: 0.6366 - policy_categorical_accuracy: 0.4022 - value_mse: 0.0937\n","epoch 347\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0525 - policy_loss: 2.3478 - value_loss: 0.6342 - policy_categorical_accuracy: 0.3903 - value_mse: 0.0931\n","epoch 348\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0333 - policy_loss: 2.3324 - value_loss: 0.6303 - policy_categorical_accuracy: 0.3984 - value_mse: 0.0919\n","epoch 349\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.0559 - policy_loss: 2.3507 - value_loss: 0.6347 - policy_categorical_accuracy: 0.3969 - value_mse: 0.0938\n","epoch 350\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.0530 - policy_loss: 2.3498 - value_loss: 0.6327 - policy_categorical_accuracy: 0.3912 - value_mse: 0.0927\n","epoch 351\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.0375 - policy_loss: 2.3358 - value_loss: 0.6311 - policy_categorical_accuracy: 0.4005 - value_mse: 0.0909\n","epoch 352\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0337 - policy_loss: 2.3253 - value_loss: 0.6378 - policy_categorical_accuracy: 0.3981 - value_mse: 0.0954\n","epoch 353\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0366 - policy_loss: 2.3282 - value_loss: 0.6378 - policy_categorical_accuracy: 0.3980 - value_mse: 0.0928\n","epoch 354\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0804 - policy_loss: 2.3817 - value_loss: 0.6280 - policy_categorical_accuracy: 0.3818 - value_mse: 0.0897\n","epoch 355\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0456 - policy_loss: 2.3404 - value_loss: 0.6345 - policy_categorical_accuracy: 0.3940 - value_mse: 0.0930\n","epoch 356\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0449 - policy_loss: 2.3422 - value_loss: 0.6320 - policy_categorical_accuracy: 0.3930 - value_mse: 0.0920\n","epoch 357\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0529 - policy_loss: 2.3499 - value_loss: 0.6322 - policy_categorical_accuracy: 0.3925 - value_mse: 0.0930\n","epoch 358\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0367 - policy_loss: 2.3339 - value_loss: 0.6319 - policy_categorical_accuracy: 0.3982 - value_mse: 0.0936\n","epoch 359\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.0190 - policy_loss: 2.3199 - value_loss: 0.6282 - policy_categorical_accuracy: 0.3918 - value_mse: 0.0915\n","epoch 360\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0400 - policy_loss: 2.3348 - value_loss: 0.6344 - policy_categorical_accuracy: 0.4016 - value_mse: 0.0932\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.19796085357666, 2.461132287979126, 0.6659231185913086, 0.37950000166893005, 0.10695694386959076]\n","epoch 361\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0576 - policy_loss: 2.3514 - value_loss: 0.6354 - policy_categorical_accuracy: 0.3956 - value_mse: 0.0931\n","epoch 362\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0289 - policy_loss: 2.3285 - value_loss: 0.6295 - policy_categorical_accuracy: 0.3985 - value_mse: 0.0917\n","epoch 363\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.0571 - policy_loss: 2.3509 - value_loss: 0.6352 - policy_categorical_accuracy: 0.3943 - value_mse: 0.0931\n","epoch 364\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0074 - policy_loss: 2.3064 - value_loss: 0.6301 - policy_categorical_accuracy: 0.4001 - value_mse: 0.0912\n","epoch 365\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0393 - policy_loss: 2.3396 - value_loss: 0.6287 - policy_categorical_accuracy: 0.3907 - value_mse: 0.0929\n","epoch 366\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0525 - policy_loss: 2.3510 - value_loss: 0.6305 - policy_categorical_accuracy: 0.3981 - value_mse: 0.0925\n","epoch 367\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.0641 - policy_loss: 2.3628 - value_loss: 0.6303 - policy_categorical_accuracy: 0.3885 - value_mse: 0.0903\n","epoch 368\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0343 - policy_loss: 2.3329 - value_loss: 0.6304 - policy_categorical_accuracy: 0.3923 - value_mse: 0.0915\n","epoch 369\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0302 - policy_loss: 2.3286 - value_loss: 0.6306 - policy_categorical_accuracy: 0.4022 - value_mse: 0.0929\n","epoch 370\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0235 - policy_loss: 2.3265 - value_loss: 0.6260 - policy_categorical_accuracy: 0.4033 - value_mse: 0.0918\n","epoch 371\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0362 - policy_loss: 2.3309 - value_loss: 0.6342 - policy_categorical_accuracy: 0.3955 - value_mse: 0.0933\n","epoch 372\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.0208 - policy_loss: 2.3218 - value_loss: 0.6279 - policy_categorical_accuracy: 0.3922 - value_mse: 0.0908\n","epoch 373\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.0428 - policy_loss: 2.3414 - value_loss: 0.6302 - policy_categorical_accuracy: 0.3927 - value_mse: 0.0911\n","epoch 374\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0102 - policy_loss: 2.3108 - value_loss: 0.6282 - policy_categorical_accuracy: 0.4020 - value_mse: 0.0922\n","epoch 375\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 2.9939 - policy_loss: 2.2896 - value_loss: 0.6331 - policy_categorical_accuracy: 0.4098 - value_mse: 0.0931\n","epoch 376\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.0208 - policy_loss: 2.3221 - value_loss: 0.6275 - policy_categorical_accuracy: 0.3947 - value_mse: 0.0900\n","epoch 377\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.0450 - policy_loss: 2.3445 - value_loss: 0.6293 - policy_categorical_accuracy: 0.3961 - value_mse: 0.0899\n","epoch 378\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0302 - policy_loss: 2.3340 - value_loss: 0.6250 - policy_categorical_accuracy: 0.3994 - value_mse: 0.0906\n","epoch 379\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.0445 - policy_loss: 2.3440 - value_loss: 0.6292 - policy_categorical_accuracy: 0.3946 - value_mse: 0.0907\n","epoch 380\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0071 - policy_loss: 2.3055 - value_loss: 0.6303 - policy_categorical_accuracy: 0.4004 - value_mse: 0.0922\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.1619651317596436, 2.4113714694976807, 0.6793094873428345, 0.3882000148296356, 0.11226271092891693]\n","epoch 381\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 3.0151 - policy_loss: 2.3177 - value_loss: 0.6261 - policy_categorical_accuracy: 0.4014 - value_mse: 0.0905\n","epoch 382\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 132ms/step - loss: 3.0206 - policy_loss: 2.3202 - value_loss: 0.6291 - policy_categorical_accuracy: 0.4005 - value_mse: 0.0925\n","epoch 383\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0147 - policy_loss: 2.3164 - value_loss: 0.6270 - policy_categorical_accuracy: 0.3994 - value_mse: 0.0916\n","epoch 384\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 2.9941 - policy_loss: 2.2964 - value_loss: 0.6264 - policy_categorical_accuracy: 0.4006 - value_mse: 0.0903\n","epoch 385\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.0217 - policy_loss: 2.3185 - value_loss: 0.6319 - policy_categorical_accuracy: 0.3966 - value_mse: 0.0916\n","epoch 386\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0382 - policy_loss: 2.3319 - value_loss: 0.6350 - policy_categorical_accuracy: 0.3938 - value_mse: 0.0939\n","epoch 387\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0116 - policy_loss: 2.3105 - value_loss: 0.6298 - policy_categorical_accuracy: 0.4030 - value_mse: 0.0898\n","epoch 388\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 2.9789 - policy_loss: 2.2776 - value_loss: 0.6300 - policy_categorical_accuracy: 0.4064 - value_mse: 0.0896\n","epoch 389\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 135ms/step - loss: 3.0335 - policy_loss: 2.3312 - value_loss: 0.6309 - policy_categorical_accuracy: 0.3886 - value_mse: 0.0905\n","epoch 390\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0129 - policy_loss: 2.3152 - value_loss: 0.6263 - policy_categorical_accuracy: 0.3930 - value_mse: 0.0878\n","epoch 391\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9976 - policy_loss: 2.3039 - value_loss: 0.6223 - policy_categorical_accuracy: 0.3981 - value_mse: 0.0899\n","epoch 392\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 132ms/step - loss: 3.0281 - policy_loss: 2.3297 - value_loss: 0.6270 - policy_categorical_accuracy: 0.3947 - value_mse: 0.0914\n","epoch 393\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 132ms/step - loss: 3.0012 - policy_loss: 2.2992 - value_loss: 0.6306 - policy_categorical_accuracy: 0.4102 - value_mse: 0.0926\n","epoch 394\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 3.0225 - policy_loss: 2.3219 - value_loss: 0.6291 - policy_categorical_accuracy: 0.4052 - value_mse: 0.0911\n","epoch 395\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 3.0160 - policy_loss: 2.3177 - value_loss: 0.6269 - policy_categorical_accuracy: 0.3985 - value_mse: 0.0901\n","epoch 396\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 2.9871 - policy_loss: 2.2910 - value_loss: 0.6247 - policy_categorical_accuracy: 0.4109 - value_mse: 0.0886\n","epoch 397\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 2.9940 - policy_loss: 2.2975 - value_loss: 0.6251 - policy_categorical_accuracy: 0.4090 - value_mse: 0.0896\n","epoch 398\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9809 - policy_loss: 2.2861 - value_loss: 0.6234 - policy_categorical_accuracy: 0.4029 - value_mse: 0.0876\n","epoch 399\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9825 - policy_loss: 2.2819 - value_loss: 0.6292 - policy_categorical_accuracy: 0.4051 - value_mse: 0.0921\n","epoch 400\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9854 - policy_loss: 2.2861 - value_loss: 0.6278 - policy_categorical_accuracy: 0.4036 - value_mse: 0.0902\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","val = [3.178145408630371, 2.45147967338562, 0.6552021503448486, 0.38370001316070557, 0.10121665149927139]\n","epoch 401\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 2.9583 - policy_loss: 2.2632 - value_loss: 0.6236 - policy_categorical_accuracy: 0.4110 - value_mse: 0.0870\n","epoch 402\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 2.9953 - policy_loss: 2.2973 - value_loss: 0.6266 - policy_categorical_accuracy: 0.4033 - value_mse: 0.0867\n","epoch 403\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 2.9977 - policy_loss: 2.2997 - value_loss: 0.6266 - policy_categorical_accuracy: 0.4007 - value_mse: 0.0886\n","epoch 404\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 2.9954 - policy_loss: 2.2978 - value_loss: 0.6262 - policy_categorical_accuracy: 0.4048 - value_mse: 0.0893\n","epoch 405\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 136ms/step - loss: 2.9973 - policy_loss: 2.3019 - value_loss: 0.6239 - policy_categorical_accuracy: 0.3924 - value_mse: 0.0881\n","epoch 406\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 134ms/step - loss: 2.9859 - policy_loss: 2.2920 - value_loss: 0.6224 - policy_categorical_accuracy: 0.4081 - value_mse: 0.0884\n","epoch 407\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 136ms/step - loss: 2.9936 - policy_loss: 2.2976 - value_loss: 0.6246 - policy_categorical_accuracy: 0.3986 - value_mse: 0.0886\n","epoch 408\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9889 - policy_loss: 2.2921 - value_loss: 0.6253 - policy_categorical_accuracy: 0.3997 - value_mse: 0.0898\n","epoch 409\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 3.0108 - policy_loss: 2.3083 - value_loss: 0.6310 - policy_categorical_accuracy: 0.3949 - value_mse: 0.0911\n","epoch 410\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 11s 133ms/step - loss: 2.9762 - policy_loss: 2.2735 - value_loss: 0.6312 - policy_categorical_accuracy: 0.4045 - value_mse: 0.0920\n","epoch 411\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 132ms/step - loss: 2.9741 - policy_loss: 2.2735 - value_loss: 0.6292 - policy_categorical_accuracy: 0.4041 - value_mse: 0.0908\n","epoch 412\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","79/79 [==============================] - 10s 133ms/step - loss: 2.9974 - policy_loss: 2.3032 - value_loss: 0.6228 - policy_categorical_accuracy: 0.3996 - value_mse: 0.0883\n","epoch 413\n","r.shape = (10000, 19, 19, 31)\n","nbExamples = 10000\n","38/79 [=============>................] - ETA: 5s - loss: 2.9931 - policy_loss: 2.3023 - value_loss: 0.6194 - policy_categorical_accuracy: 0.4007 - value_mse: 0.0887Traceback (most recent call last):\n","  File \"golois.py\", line 92, in <module>\n","    epochs=1, batch_size=batch)\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1656, in fit\n","    callbacks.on_train_batch_end(end_step, logs)\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\", line 476, in on_train_batch_end\n","    self._call_batch_hook(ModeKeys.TRAIN, \"end\", batch, logs=logs)\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\", line 323, in _call_batch_hook\n","    self._call_batch_end_hook(mode, batch, logs)\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\", line 346, in _call_batch_end_hook\n","    self._call_batch_hook_helper(hook_name, batch, logs)\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\", line 394, in _call_batch_hook_helper\n","    hook(batch, logs)\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\", line 1094, in on_train_batch_end\n","    self._batch_update_progbar(batch, logs)\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\", line 1170, in _batch_update_progbar\n","    logs = tf_utils.sync_to_numpy_or_python_type(logs)\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\", line 665, in sync_to_numpy_or_python_type\n","    return tf.nest.map_structure(_to_single_numpy_or_python_type, tensors)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\", line 917, in map_structure\n","    structure[0], [func(*x) for x in entries],\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\", line 917, in <listcomp>\n","    structure[0], [func(*x) for x in entries],\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\", line 658, in _to_single_numpy_or_python_type\n","    t = t.numpy()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1155, in numpy\n","    maybe_arr = self._numpy()  # pylint: disable=protected-access\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1121, in _numpy\n","    return self._numpy_internal()\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","source":["\"\"\"import tensorflow as tf\n","import tensorflow.keras as keras\n","import numpy as np\n","from tensorflow.keras import layers \n","from tensorflow.keras import regularizers\n","import gc\n","\n","import golois\n","\n","planes = 31\n","moves = 361\n","N = 10000\n","epochs = 600\n","batch = 128\n","filters = 30\n","\n","\n","def mixconv(x, filters):\n","  G = len(filters)\n","  y = []\n","  for i, (xi, fi) in enumerate(zip(tf.split(x, G, axis=-1), filters)):\n","    gi = layers.DepthwiseConv2D(2*(i+1) + 1, strides=1,padding= 'same')(xi)\n","    gi = layers.BatchNormalization()(gi)\n","    gi = layers.Activation('swish')(gi)\n","    y.append(gi)\n","  return tf.concat(y, axis=-1)\n","\n","def bottleneck_block(x, expand=152, squeeze=filters):\n","  m = layers.Conv2D(expand, (1,1), kernel_regularizer=regularizers.l2(0.0001), use_bias = False)(x)\n","  m = layers.BatchNormalization()(m)\n","  m = layers.Activation('swish')(m)\n","  m = mixconv(m, filters=[tf.Variable(tf.random.normal([3, 3, expand, expand])), \n","                         tf.Variable(tf.random.normal([3, 3, expand, expand]))])\n","  m = layers.BatchNormalization()(m)\n","  m = layers.Activation('swish')(m)\n","  m = layers.Conv2D(squeeze, (1,1), kernel_regularizer=regularizers.l2(0.0001), use_bias = False)(m)\n","  m = layers.BatchNormalization()(m)\n","  z= layers.GlobalAveragePooling2D()(m)\n","  return layers.Add()([m, x])\n","\n","input_data = np.random.randint(2, size=(N, 19, 19, planes))\n","input_data = input_data.astype ('float32')\n","\n","policy = np.random.randint(moves, size=(N,))\n","policy = keras.utils.to_categorical (policy)\n","\n","value = np.random.randint(2, size=(N,))\n","value = value.astype ('float32')\n","\n","end = np.random.randint(2, size=(N, 19, 19, 2))\n","end = end.astype ('float32')\n","\n","groups = np.zeros((N, 19, 19, 1))\n","groups = groups.astype ('float32')\n","\n","print (\"getValidation\", flush = True)\n","golois.getValidation (input_data, policy, value, end)\n","\n","\n","input = keras.Input(shape=(19, 19, planes), name='board')\n","x = layers.Conv2D(filters, 1, activation='relu', padding='same')(input)\n","x = layers.BatchNormalization()(x)\n","for j in range(7):\n","  x = bottleneck_block(x)\n","\n","policy_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias = False, kernel_regularizer=regularizers.l2(0.0001))(x)\n","policy_head = layers.Flatten()(policy_head)\n","policy_head = layers.Activation('softmax', name='policy')(policy_head)\n","value_head = layers.GlobalAveragePooling2D()(x)\n","value_head = layers.Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(value_head)\n","value_head = layers.Dense(12, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(value_head)\n","value_head = layers.Dense(4, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(value_head)\n","value_head = layers.Dense(1, activation='sigmoid', name='value', kernel_regularizer=regularizers.l2(0.0001))(value_head)\n","\n","model = keras.Model(inputs=input, outputs=[policy_head, value_head])\n","\n","model.summary ()\n","\n","lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(0.1,100)\n","optimizer_SGDR = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n","\n","model.compile(optimizer=optimizer_SGDR,\n","              loss={'policy': 'categorical_crossentropy', 'value': 'binary_crossentropy'},\n","              loss_weights={'policy' : 1.0, 'value' : 1.0},\n","              metrics={'policy': 'categorical_accuracy', 'value': 'mse'})\n","\n","for i in range (1, epochs + 1):\n","    print ('epoch ' + str (i))\n","    golois.getBatch (input_data, policy, value, end, groups, i * N)\n","    history = model.fit(input_data,\n","                        {'policy': policy, 'value': value}, \n","                        epochs=1, batch_size=batch)\n","    if (i % 5 == 0):\n","        gc.collect ()\n","    if (i % 20 == 0):\n","        golois.getValidation (input_data, policy, value, end)\n","        val = model.evaluate (input_data,\n","                              [policy, value], verbose = 0, batch_size=batch)\n","        print (\"val =\", val)\n","        model.save ('test.h5')\n","\"\"\""],"metadata":{"id":"bSINkm2Gkd2u"},"execution_count":null,"outputs":[]}]}